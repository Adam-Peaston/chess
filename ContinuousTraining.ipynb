{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a5e8dc",
   "metadata": {},
   "source": [
    "## Plan for continuous training\n",
    "\n",
    "Here's the plan. The script boots up and checks a continuous play directory which is populated with a number of training round sub-directores. Each sub-directory is labelled in sequence and contains a self_play sub-sub-directory. The script takes stock of the contents of the latest training round self_play directory.\n",
    "\n",
    "If the number of files (tournaments) saved in the self_play directory of the latest training round is less than some minimum M, say m < M then the self-play script is kicked off to play M - m more tournaments, completing the M requred self-play tournaments and saving to the  subdirectory.\n",
    "\n",
    "If the number of files saved in the self_play directory of the latest training round m >= M then the script checks if there is already a model saved in the training round directory.\n",
    "\n",
    "If there is not a model saved in the training round directory, the script will kick off a training routine to create a new model (or load a saved model from a possibly existing previous round), compile a training dataset from the most recent k training rounds (augmented with the catalogue of known checkmate positions) and train the model to stopping. The script will then save the model in the training round sub-directory.\n",
    "\n",
    "Then the script will create a new training round directory, labelled with the next integer in the training round sequence, containing a self_play directory. At this point we can essentially continue the loop from the top.\n",
    "\n",
    "Maybe I should spin up a separate process for training as well as self-play so that its memory will be comprehensively retired when it's done..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae9f755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Current: round_12, already played: 0, left to play: 50\n",
      "Playing 50 tournaments...\n"
     ]
    }
   ],
   "source": [
    "import os, torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from chess_selfplay import harvest_checkmates\n",
    "from chess_model import TransformerModel, ChessDataset, TanhLoss, train\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "min_tournaments_each_round = 50 # A new model roughly once a day.\n",
    "model_kwargs = {'nlayers':6, 'nheads':3, 'embed_dim':12, 'dk':8, 'device':device}\n",
    "root_dir = os.path.join('data','output')\n",
    "dir_sort_key = lambda d: int(d.split('_')[-1])\n",
    "\n",
    "## LOOP STARTS - just kill the machine any old time when you have stuff to do and you can fire it up again whenever you're ready.\n",
    "while True:\n",
    "\n",
    "    # Checking where we're up to\n",
    "    training_round_dirs = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir,d))], key=dir_sort_key)\n",
    "    current_training_round_dir = training_round_dirs[-1]\n",
    "    previous_training_round_dir = training_round_dirs[-2]\n",
    "\n",
    "    # Counting how many tournaments have been played already this round\n",
    "    current_self_play_path = os.path.join(root_dir, current_training_round_dir, 'self_play')\n",
    "    if os.path.exists(current_self_play_path) and os.path.isdir(current_self_play_path):\n",
    "        number_games_played_already = len(os.listdir(current_self_play_path))\n",
    "    else:\n",
    "        os.mkdir(current_self_play_path)\n",
    "        number_games_played_already = 0\n",
    "\n",
    "    tournaments_left_to_play = min_tournaments_each_round - number_games_played_already\n",
    "    print(f'Current: {current_training_round_dir}, already played: {number_games_played_already}, left to play: {tournaments_left_to_play}')\n",
    "\n",
    "    if tournaments_left_to_play > 0:\n",
    "        \n",
    "        # self-play script to play tournaments_left_to_play more tournaments, saving to current_self_play_dir.\n",
    "        model_source_path = os.path.join(root_dir, previous_training_round_dir, 'model.pt')\n",
    "        assert os.path.exists(model_source_path) and os.path.isfile(model_source_path), 'ERROR: MODEL NOT FOUND.'\n",
    "\n",
    "        # Same base model with different look-ahead strength configuration \n",
    "        model_kwargs['load_path'] = model_source_path\n",
    "        agent0_spec = {'type':'transformer', 'kwargs':model_kwargs, 'num_simgames':150, 'max_simmoves':6, 'C':1, 'p':0.3, 'k':float('inf')}\n",
    "        agent1_spec = {'type':'transformer', 'kwargs':model_kwargs, 'num_simgames':1,   'max_simmoves':1, 'C':1, 'p':0.4, 'k':float('inf')}\n",
    "        selfplay_args = {\n",
    "            'num_workers':2, 'num_tournaments': tournaments_left_to_play, 'agents_spec': [agent0_spec, agent1_spec], \n",
    "            'num_games':1, 'starting_state':None, 'max_moves':200, 'save':True, 'result_dest':current_self_play_path\n",
    "        }\n",
    "\n",
    "        # Let's play\n",
    "        print(f'Playing {tournaments_left_to_play} tournaments...')\n",
    "        %run -i \"chess_selfplay.py\"\n",
    "        print(f'Self-play complete.')\n",
    "\n",
    "    # Extract the checkmates from the current_self_play_dir tournament games and save them in the current_training_round_dir.\n",
    "    current_round_checkmates_path = os.path.join(root_dir, current_training_round_dir, 'checkmates.pkl')\n",
    "    if not (os.path.exists(current_round_checkmates_path) and os.path.isfile(current_round_checkmates_path)):\n",
    "        _ = harvest_checkmates(os.path.join(root_dir, current_training_round_dir))\n",
    "\n",
    "    ## Namespace for chess_modeltraining.py includes:\n",
    "    ## root_dir, current_training_round_dir, model_kwargs, device\n",
    "    # modeltraining_args = {'root_dir':root_dir, 'current_training_round_dir':current_training_round_dir, 'model_kwargs':model_kwargs, 'device':device}\n",
    "    # Let's train\n",
    "    # print(f'Training a new model...')\n",
    "    # %run -i \"chess_modeltraining.py\"\n",
    "    # print(f'Training complete.')\n",
    "\n",
    "    latest_model_path = os.path.join(root_dir, current_training_round_dir, 'model.pt')\n",
    "    if not (os.path.exists(latest_model_path) and os.path.isfile(latest_model_path)):\n",
    "\n",
    "        # No model saved here yet. Create and train a new model based on the previous k rounds of self-play data.\n",
    "        # We currently have 591 tournaments saved in baseline and 191 in round1. We could use k = 10 and go from there?\n",
    "        model_kwargs['load_path'] = None # Brand new model\n",
    "        model = TransformerModel(**model_kwargs)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0, weight_decay=0)\n",
    "        loss_fn = TanhLoss()\n",
    "        dataset = ChessDataset(root_dir=root_dir, look_back=10, device=device)\n",
    "        train_set, test_set = random_split(dataset, [int(len(dataset)*0.8), len(dataset) - int(len(dataset)*0.8)])\n",
    "        train_loader = DataLoader(train_set, batch_size=1000, shuffle=True, num_workers=0)\n",
    "        test_loader = DataLoader(test_set, batch_size=1000, shuffle=True, num_workers=0)\n",
    "        print(f'Training on {len(train_set):,.0f} examples in {len(train_loader):,.0f} batches.')\n",
    "\n",
    "        # Train on the data\n",
    "        model_dest = os.path.join(root_dir, current_training_round_dir, 'model.pt')\n",
    "        model = train(model, loss_fn, optimizer, train_loader, test_loader, warmup_passes=4, max_lr=1e-4, save_dir=model_dest, slope_threshold=0, stop_after=10)\n",
    "        \n",
    "        # Clean up CUDA memory\n",
    "        del model, optimizer, loss_fn, dataset, train_set, test_set, train_loader, test_loader\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    torch.cuda.empty_cache() ## again maybe?\n",
    "        \n",
    "    # Create next training round directory containing self_play sub-directory, and start loop from the top.\n",
    "    next_index = int(os.path.split(current_training_round_dir)[-1].split('_')[-1]) + 1\n",
    "    next_training_round_dir = f'round_{next_index}'\n",
    "    print(f'Creating next training round directory {next_training_round_dir}')\n",
    "    next_training_round_path = os.path.join(root_dir, next_training_round_dir)\n",
    "    os.mkdir(next_training_round_path)\n",
    "    next_training_round_self_play_path = os.path.join(next_training_round_path, 'self_play')\n",
    "    os.mkdir(next_training_round_self_play_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090eddaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
