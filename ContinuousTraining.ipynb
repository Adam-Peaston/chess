{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a5e8dc",
   "metadata": {},
   "source": [
    "## Plan for continuous training\n",
    "\n",
    "Here's the plan. The script boots up and checks a continuous play directory which is populated with a number of training round sub-directores. Each sub-directory is labelled in sequence and contains a self_play sub-sub-directory. The script takes stock of the contents of the latest training round self_play directory.\n",
    "\n",
    "If the number of files (tournaments) saved in the self_play directory of the latest training round is less than some minimum M, say m < M then the self-play script is kicked off to play M - m more tournaments, completing the M requred self-play tournaments and saving to the  subdirectory.\n",
    "\n",
    "If the number of files saved in the self_play directory of the latest training round m >= M then the script checks if there is already a model saved in the training round directory.\n",
    "\n",
    "If there is not a model saved in the training round directory, the script will kick off a training routine to create a new model (or load a saved model from a possibly existing previous round), compile a training dataset from the most recent k training rounds (augmented with the catalogue of known checkmate positions) and train the model to stopping. The script will then save the model in the training round sub-directory.\n",
    "\n",
    "Then the script will create a new training round directory, labelled with the next integer in the training round sequence, containing a self_play directory. At this point we can essentially continue the loop from the top.\n",
    "\n",
    "Maybe I should spin up a separate process for training as well as self-play so that its memory will be comprehensively retired when it's done..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae9f755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Current: round_6, already played: 87, left to play: -37\n",
      "Training brand new model.\n",
      "Training on 154,859 examples in 155 batches.\n",
      "Epoch: 1, train loss: 3.44784, test loss: 3.44998, slope: 0.000, stopping count: 0\n",
      "Epoch: 2, train loss: 3.44711, test loss: 3.44527, slope: 0.000, stopping count: 0\n",
      "Epoch: 3, train loss: 3.44186, test loss: 3.44236, slope: 0.000, stopping count: 0\n",
      "Epoch: 4, train loss: 3.43994, test loss: 3.44102, slope: -1.000, stopping count: 0\n",
      "Epoch: 5, train loss: 3.43864, test loss: 3.44063, slope: -1.000, stopping count: 0\n",
      "Epoch: 6, train loss: 3.43792, test loss: 3.43946, slope: -1.000, stopping count: 0\n",
      "Epoch: 7, train loss: 3.43784, test loss: 3.43916, slope: -1.000, stopping count: 0\n",
      "Epoch: 8, train loss: 3.43764, test loss: 3.43904, slope: -0.957, stopping count: 0\n",
      "Epoch: 9, train loss: 3.43751, test loss: 3.43893, slope: -0.965, stopping count: 0\n",
      "Epoch: 10, train loss: 3.43737, test loss: 3.43871, slope: -0.921, stopping count: 0\n",
      "Epoch: 11, train loss: 3.43739, test loss: 3.43898, slope: -0.614, stopping count: 0\n",
      "Epoch: 12, train loss: 3.43707, test loss: 3.43850, slope: -0.801, stopping count: 0\n",
      "Epoch: 13, train loss: 3.43710, test loss: 3.43858, slope: -0.885, stopping count: 0\n",
      "Epoch: 14, train loss: 3.43719, test loss: 3.43885, slope: -0.594, stopping count: 0\n",
      "Epoch: 15, train loss: 3.43697, test loss: 3.43838, slope: -0.637, stopping count: 0\n",
      "Epoch: 16, train loss: 3.43697, test loss: 3.43846, slope: -0.729, stopping count: 0\n",
      "Epoch: 17, train loss: 3.43700, test loss: 3.43850, slope: -0.578, stopping count: 0\n",
      "Epoch: 18, train loss: 3.43700, test loss: 3.43866, slope: -0.429, stopping count: 0\n",
      "Epoch: 19, train loss: 3.43706, test loss: 3.43891, slope: -0.075, stopping count: 0\n",
      "Epoch: 20, train loss: 3.43681, test loss: 3.43878, slope: 0.047, stopping count: 1\n",
      "Epoch: 21, train loss: 3.43693, test loss: 3.43908, slope: 0.605, stopping count: 2\n",
      "Epoch: 22, train loss: 3.43690, test loss: 3.43859, slope: 0.451, stopping count: 3\n",
      "Epoch: 23, train loss: 3.43701, test loss: 3.43844, slope: 0.186, stopping count: 4\n",
      "Epoch: 24, train loss: 3.43689, test loss: 3.43832, slope: -0.041, stopping count: 0\n",
      "Epoch: 25, train loss: 3.43684, test loss: 3.43894, slope: 0.096, stopping count: 1\n",
      "Epoch: 26, train loss: 3.43690, test loss: 3.43842, slope: -0.040, stopping count: 0\n",
      "Epoch: 27, train loss: 3.43682, test loss: 3.43861, slope: 0.069, stopping count: 1\n",
      "Epoch: 28, train loss: 3.43688, test loss: 3.43832, slope: -0.086, stopping count: 0\n",
      "Epoch: 29, train loss: 3.43670, test loss: 3.43908, slope: 0.022, stopping count: 1\n",
      "Epoch: 30, train loss: 3.43694, test loss: 3.43943, slope: 0.259, stopping count: 2\n",
      "Epoch: 31, train loss: 3.43680, test loss: 3.43868, slope: 0.166, stopping count: 3\n",
      "Epoch: 32, train loss: 3.43667, test loss: 3.43811, slope: -0.029, stopping count: 0\n",
      "Epoch: 33, train loss: 3.43687, test loss: 3.43894, slope: -0.015, stopping count: 0\n",
      "Epoch: 34, train loss: 3.43672, test loss: 3.43814, slope: -0.148, stopping count: 0\n",
      "Epoch: 35, train loss: 3.43649, test loss: 3.43808, slope: -0.286, stopping count: 0\n",
      "Epoch: 36, train loss: 3.43679, test loss: 3.43844, slope: -0.302, stopping count: 0\n",
      "Epoch: 37, train loss: 3.43651, test loss: 3.43802, slope: -0.350, stopping count: 0\n",
      "Epoch: 38, train loss: 3.43665, test loss: 3.43849, slope: -0.332, stopping count: 0\n",
      "Epoch: 39, train loss: 3.43665, test loss: 3.43815, slope: -0.372, stopping count: 0\n",
      "Epoch: 40, train loss: 3.43676, test loss: 3.43813, slope: -0.415, stopping count: 0\n",
      "Epoch: 41, train loss: 3.43663, test loss: 3.43822, slope: -0.355, stopping count: 0\n",
      "Epoch: 42, train loss: 3.43650, test loss: 3.43837, slope: -0.342, stopping count: 0\n",
      "Epoch: 43, train loss: 3.43658, test loss: 3.43811, slope: -0.387, stopping count: 0\n",
      "Epoch: 44, train loss: 3.43651, test loss: 3.43822, slope: -0.393, stopping count: 0\n",
      "Epoch: 45, train loss: 3.43641, test loss: 3.43878, slope: -0.333, stopping count: 0\n",
      "Epoch: 46, train loss: 3.43646, test loss: 3.43889, slope: -0.231, stopping count: 0\n",
      "Epoch: 47, train loss: 3.43652, test loss: 3.43879, slope: -0.206, stopping count: 0\n",
      "Epoch: 48, train loss: 3.43641, test loss: 3.43816, slope: -0.245, stopping count: 0\n",
      "Epoch: 49, train loss: 3.43665, test loss: 3.43800, slope: -0.239, stopping count: 0\n",
      "Epoch: 50, train loss: 3.43643, test loss: 3.43835, slope: -0.235, stopping count: 0\n",
      "Epoch: 51, train loss: 3.43645, test loss: 3.43802, slope: -0.302, stopping count: 0\n",
      "Epoch: 52, train loss: 3.43646, test loss: 3.43800, slope: -0.341, stopping count: 0\n",
      "Epoch: 53, train loss: 3.43645, test loss: 3.43822, slope: -0.336, stopping count: 0\n",
      "Epoch: 54, train loss: 3.43629, test loss: 3.43791, slope: -0.359, stopping count: 0\n",
      "Epoch: 55, train loss: 3.43658, test loss: 3.43807, slope: -0.407, stopping count: 0\n",
      "Epoch: 56, train loss: 3.43648, test loss: 3.43786, slope: -0.431, stopping count: 0\n",
      "Epoch: 57, train loss: 3.43632, test loss: 3.43802, slope: -0.373, stopping count: 0\n",
      "Epoch: 58, train loss: 3.43612, test loss: 3.43784, slope: -0.402, stopping count: 0\n",
      "Epoch: 59, train loss: 3.43614, test loss: 3.43780, slope: -0.437, stopping count: 0\n",
      "Epoch: 60, train loss: 3.43643, test loss: 3.43774, slope: -0.465, stopping count: 0\n",
      "Epoch: 61, train loss: 3.43627, test loss: 3.43811, slope: -0.405, stopping count: 0\n",
      "Epoch: 62, train loss: 3.43612, test loss: 3.43783, slope: -0.436, stopping count: 0\n",
      "Epoch: 63, train loss: 3.43611, test loss: 3.43801, slope: -0.476, stopping count: 0\n",
      "Epoch: 64, train loss: 3.43617, test loss: 3.43823, slope: -0.440, stopping count: 0\n",
      "Epoch: 65, train loss: 3.43629, test loss: 3.43784, slope: -0.387, stopping count: 0\n",
      "Epoch: 66, train loss: 3.43620, test loss: 3.43803, slope: -0.383, stopping count: 0\n",
      "Epoch: 67, train loss: 3.43615, test loss: 3.43801, slope: -0.405, stopping count: 0\n",
      "Epoch: 68, train loss: 3.43619, test loss: 3.43774, slope: -0.439, stopping count: 0\n",
      "Epoch: 69, train loss: 3.43617, test loss: 3.43777, slope: -0.498, stopping count: 0\n",
      "Epoch: 70, train loss: 3.43609, test loss: 3.43770, slope: -0.511, stopping count: 0\n",
      "Epoch: 71, train loss: 3.43606, test loss: 3.43959, slope: -0.166, stopping count: 0\n",
      "Epoch: 72, train loss: 3.43618, test loss: 3.43859, slope: -0.120, stopping count: 0\n",
      "Epoch: 73, train loss: 3.43622, test loss: 3.43792, slope: -0.152, stopping count: 0\n",
      "Epoch: 74, train loss: 3.43600, test loss: 3.43773, slope: -0.178, stopping count: 0\n",
      "Epoch: 75, train loss: 3.43605, test loss: 3.43790, slope: -0.168, stopping count: 0\n",
      "Epoch: 76, train loss: 3.43606, test loss: 3.43818, slope: -0.155, stopping count: 0\n",
      "Epoch: 77, train loss: 3.43610, test loss: 3.43755, slope: -0.184, stopping count: 0\n",
      "Epoch: 78, train loss: 3.43597, test loss: 3.43766, slope: -0.208, stopping count: 0\n",
      "Epoch: 79, train loss: 3.43612, test loss: 3.43755, slope: -0.244, stopping count: 0\n",
      "Epoch: 80, train loss: 3.43600, test loss: 3.43757, slope: -0.268, stopping count: 0\n",
      "Epoch: 81, train loss: 3.43607, test loss: 3.43771, slope: -0.283, stopping count: 0\n",
      "Epoch: 82, train loss: 3.43598, test loss: 3.43754, slope: -0.303, stopping count: 0\n",
      "Epoch: 83, train loss: 3.43595, test loss: 3.43787, slope: -0.292, stopping count: 0\n",
      "Epoch: 84, train loss: 3.43611, test loss: 3.43762, slope: -0.306, stopping count: 0\n",
      "Epoch: 85, train loss: 3.43593, test loss: 3.43758, slope: -0.330, stopping count: 0\n",
      "Epoch: 86, train loss: 3.43594, test loss: 3.43783, slope: -0.327, stopping count: 0\n",
      "Epoch: 87, train loss: 3.43596, test loss: 3.43798, slope: -0.314, stopping count: 0\n",
      "Epoch: 88, train loss: 3.43588, test loss: 3.43828, slope: -0.282, stopping count: 0\n",
      "Epoch: 89, train loss: 3.43595, test loss: 3.43771, slope: -0.250, stopping count: 0\n",
      "Epoch: 90, train loss: 3.43576, test loss: 3.43750, slope: -0.264, stopping count: 0\n",
      "Epoch: 91, train loss: 3.43581, test loss: 3.43749, slope: -0.233, stopping count: 0\n",
      "Epoch: 92, train loss: 3.43578, test loss: 3.43747, slope: -0.249, stopping count: 0\n",
      "Epoch: 93, train loss: 3.43586, test loss: 3.43789, slope: -0.199, stopping count: 0\n",
      "Epoch: 94, train loss: 3.43584, test loss: 3.43744, slope: -0.215, stopping count: 0\n",
      "Epoch: 95, train loss: 3.43576, test loss: 3.43819, slope: -0.183, stopping count: 0\n",
      "Epoch: 96, train loss: 3.43590, test loss: 3.43774, slope: -0.185, stopping count: 0\n",
      "Epoch: 97, train loss: 3.43574, test loss: 3.43807, slope: -0.169, stopping count: 0\n",
      "Epoch: 98, train loss: 3.43568, test loss: 3.43728, slope: -0.182, stopping count: 0\n",
      "Epoch: 99, train loss: 3.43578, test loss: 3.43743, slope: -0.182, stopping count: 0\n",
      "Epoch: 100, train loss: 3.43576, test loss: 3.43756, slope: -0.190, stopping count: 0\n",
      "Epoch: 101, train loss: 3.43563, test loss: 3.43761, slope: -0.194, stopping count: 0\n",
      "Epoch: 102, train loss: 3.43567, test loss: 3.43763, slope: -0.198, stopping count: 0\n",
      "Epoch: 103, train loss: 3.43583, test loss: 3.43787, slope: -0.189, stopping count: 0\n",
      "Epoch: 104, train loss: 3.43570, test loss: 3.43751, slope: -0.198, stopping count: 0\n",
      "Epoch: 105, train loss: 3.43568, test loss: 3.43755, slope: -0.193, stopping count: 0\n",
      "Epoch: 106, train loss: 3.43566, test loss: 3.43779, slope: -0.188, stopping count: 0\n",
      "Epoch: 107, train loss: 3.43585, test loss: 3.43745, slope: -0.202, stopping count: 0\n",
      "Epoch: 108, train loss: 3.43556, test loss: 3.43753, slope: -0.208, stopping count: 0\n",
      "Epoch: 109, train loss: 3.43568, test loss: 3.43833, slope: -0.171, stopping count: 0\n",
      "Epoch: 110, train loss: 3.43572, test loss: 3.43730, slope: -0.189, stopping count: 0\n",
      "Epoch: 111, train loss: 3.43584, test loss: 3.43761, slope: -0.195, stopping count: 0\n",
      "Epoch: 112, train loss: 3.43556, test loss: 3.43753, slope: -0.201, stopping count: 0\n",
      "Epoch: 113, train loss: 3.43556, test loss: 3.43853, slope: -0.158, stopping count: 0\n",
      "Epoch: 114, train loss: 3.43581, test loss: 3.43731, slope: -0.175, stopping count: 0\n",
      "Epoch: 115, train loss: 3.43554, test loss: 3.43743, slope: -0.189, stopping count: 0\n",
      "Epoch: 116, train loss: 3.43562, test loss: 3.43743, slope: -0.198, stopping count: 0\n",
      "Epoch: 117, train loss: 3.43568, test loss: 3.43731, slope: -0.218, stopping count: 0\n",
      "Epoch: 118, train loss: 3.43557, test loss: 3.43743, slope: -0.226, stopping count: 0\n",
      "Epoch: 119, train loss: 3.43558, test loss: 3.43732, slope: -0.246, stopping count: 0\n",
      "Epoch: 120, train loss: 3.43565, test loss: 3.43729, slope: -0.258, stopping count: 0\n",
      "Epoch: 121, train loss: 3.43548, test loss: 3.43724, slope: -0.260, stopping count: 0\n",
      "Epoch: 122, train loss: 3.43560, test loss: 3.43729, slope: -0.270, stopping count: 0\n",
      "Epoch: 123, train loss: 3.43546, test loss: 3.43743, slope: -0.279, stopping count: 0\n",
      "Epoch: 124, train loss: 3.43547, test loss: 3.43705, slope: -0.274, stopping count: 0\n",
      "Epoch: 125, train loss: 3.43553, test loss: 3.43713, slope: -0.285, stopping count: 0\n",
      "Epoch: 126, train loss: 3.43553, test loss: 3.43698, slope: -0.294, stopping count: 0\n",
      "Epoch: 127, train loss: 3.43558, test loss: 3.43708, slope: -0.296, stopping count: 0\n",
      "Epoch: 128, train loss: 3.43538, test loss: 3.43702, slope: -0.310, stopping count: 0\n",
      "Epoch: 129, train loss: 3.43545, test loss: 3.43748, slope: -0.310, stopping count: 0\n",
      "Epoch: 130, train loss: 3.43548, test loss: 3.43713, slope: -0.318, stopping count: 0\n",
      "Epoch: 131, train loss: 3.43551, test loss: 3.43717, slope: -0.322, stopping count: 0\n",
      "Epoch: 132, train loss: 3.43536, test loss: 3.43702, slope: -0.333, stopping count: 0\n",
      "Epoch: 133, train loss: 3.43553, test loss: 3.43714, slope: -0.336, stopping count: 0\n",
      "Epoch: 134, train loss: 3.43539, test loss: 3.43759, slope: -0.327, stopping count: 0\n",
      "Epoch: 135, train loss: 3.43534, test loss: 3.43807, slope: -0.308, stopping count: 0\n",
      "Epoch: 136, train loss: 3.43547, test loss: 3.43837, slope: -0.274, stopping count: 0\n",
      "Epoch: 137, train loss: 3.43532, test loss: 3.43699, slope: -0.290, stopping count: 0\n",
      "Epoch: 138, train loss: 3.43538, test loss: 3.43804, slope: -0.268, stopping count: 0\n",
      "Epoch: 139, train loss: 3.43538, test loss: 3.43698, slope: -0.287, stopping count: 0\n",
      "Epoch: 140, train loss: 3.43545, test loss: 3.43699, slope: -0.299, stopping count: 0\n",
      "Epoch: 141, train loss: 3.43541, test loss: 3.43727, slope: -0.397, stopping count: 0\n",
      "Epoch: 142, train loss: 3.43523, test loss: 3.43739, slope: -0.395, stopping count: 0\n",
      "Epoch: 143, train loss: 3.43521, test loss: 3.43685, slope: -0.363, stopping count: 0\n",
      "Epoch: 144, train loss: 3.43528, test loss: 3.43701, slope: -0.378, stopping count: 0\n",
      "Epoch: 145, train loss: 3.43528, test loss: 3.43683, slope: -0.390, stopping count: 0\n",
      "Epoch: 146, train loss: 3.43517, test loss: 3.43773, slope: -0.369, stopping count: 0\n",
      "Epoch: 147, train loss: 3.43533, test loss: 3.43723, slope: -0.373, stopping count: 0\n",
      "Epoch: 148, train loss: 3.43526, test loss: 3.43723, slope: -0.376, stopping count: 0\n",
      "Epoch: 149, train loss: 3.43514, test loss: 3.43707, slope: -0.379, stopping count: 0\n",
      "Epoch: 150, train loss: 3.43529, test loss: 3.43702, slope: -0.391, stopping count: 0\n",
      "Epoch: 151, train loss: 3.43518, test loss: 3.43699, slope: -0.382, stopping count: 0\n",
      "Epoch: 152, train loss: 3.43513, test loss: 3.43693, slope: -0.397, stopping count: 0\n",
      "Epoch: 153, train loss: 3.43525, test loss: 3.43690, slope: -0.419, stopping count: 0\n",
      "Epoch: 154, train loss: 3.43512, test loss: 3.43718, slope: -0.421, stopping count: 0\n",
      "Epoch: 155, train loss: 3.43511, test loss: 3.43750, slope: -0.411, stopping count: 0\n",
      "Epoch: 156, train loss: 3.43519, test loss: 3.43714, slope: -0.414, stopping count: 0\n",
      "Epoch: 157, train loss: 3.43516, test loss: 3.43762, slope: -0.403, stopping count: 0\n",
      "Epoch: 158, train loss: 3.43511, test loss: 3.43707, slope: -0.410, stopping count: 0\n",
      "Epoch: 159, train loss: 3.43509, test loss: 3.43663, slope: -0.395, stopping count: 0\n",
      "Epoch: 160, train loss: 3.43512, test loss: 3.43710, slope: -0.398, stopping count: 0\n",
      "Epoch: 161, train loss: 3.43514, test loss: 3.43729, slope: -0.393, stopping count: 0\n",
      "Epoch: 162, train loss: 3.43505, test loss: 3.43680, slope: -0.407, stopping count: 0\n",
      "Epoch: 163, train loss: 3.43499, test loss: 3.43691, slope: -0.422, stopping count: 0\n",
      "Epoch: 164, train loss: 3.43503, test loss: 3.43672, slope: -0.439, stopping count: 0\n",
      "Epoch: 165, train loss: 3.43508, test loss: 3.43661, slope: -0.445, stopping count: 0\n",
      "Epoch: 166, train loss: 3.43508, test loss: 3.43715, slope: -0.444, stopping count: 0\n",
      "Epoch: 167, train loss: 3.43495, test loss: 3.43663, slope: -0.463, stopping count: 0\n",
      "Epoch: 168, train loss: 3.43499, test loss: 3.43663, slope: -0.479, stopping count: 0\n",
      "Epoch: 169, train loss: 3.43510, test loss: 3.43672, slope: -0.495, stopping count: 0\n",
      "Epoch: 170, train loss: 3.43504, test loss: 3.43684, slope: -0.502, stopping count: 0\n",
      "Epoch: 171, train loss: 3.43496, test loss: 3.43670, slope: -0.507, stopping count: 0\n",
      "Epoch: 172, train loss: 3.43502, test loss: 3.43679, slope: -0.515, stopping count: 0\n",
      "Epoch: 173, train loss: 3.43494, test loss: 3.43670, slope: -0.514, stopping count: 0\n",
      "Epoch: 174, train loss: 3.43495, test loss: 3.43682, slope: -0.520, stopping count: 0\n",
      "Epoch: 175, train loss: 3.43491, test loss: 3.43675, slope: -0.505, stopping count: 0\n",
      "Epoch: 176, train loss: 3.43502, test loss: 3.43680, slope: -0.511, stopping count: 0\n",
      "Epoch: 177, train loss: 3.43489, test loss: 3.43669, slope: -0.516, stopping count: 0\n",
      "Epoch: 178, train loss: 3.43502, test loss: 3.43677, slope: -0.522, stopping count: 0\n",
      "Epoch: 179, train loss: 3.43489, test loss: 3.43655, slope: -0.522, stopping count: 0\n",
      "Epoch: 180, train loss: 3.43479, test loss: 3.43673, slope: -0.528, stopping count: 0\n",
      "Epoch: 181, train loss: 3.43484, test loss: 3.43697, slope: -0.530, stopping count: 0\n",
      "Epoch: 182, train loss: 3.43489, test loss: 3.43691, slope: -0.529, stopping count: 0\n",
      "Epoch: 183, train loss: 3.43487, test loss: 3.43681, slope: -0.536, stopping count: 0\n",
      "Epoch: 184, train loss: 3.43477, test loss: 3.43649, slope: -0.532, stopping count: 0\n",
      "Epoch: 185, train loss: 3.43479, test loss: 3.43674, slope: -0.526, stopping count: 0\n",
      "Epoch: 186, train loss: 3.43498, test loss: 3.43700, slope: -0.522, stopping count: 0\n",
      "Epoch: 187, train loss: 3.43474, test loss: 3.43689, slope: -0.524, stopping count: 0\n",
      "Epoch: 188, train loss: 3.43483, test loss: 3.43666, slope: -0.530, stopping count: 0\n",
      "Epoch: 189, train loss: 3.43473, test loss: 3.43643, slope: -0.507, stopping count: 0\n",
      "Epoch: 190, train loss: 3.43482, test loss: 3.43698, slope: -0.503, stopping count: 0\n",
      "Epoch: 191, train loss: 3.43483, test loss: 3.43828, slope: -0.454, stopping count: 0\n",
      "Epoch: 192, train loss: 3.43480, test loss: 3.43662, slope: -0.461, stopping count: 0\n",
      "Epoch: 193, train loss: 3.43478, test loss: 3.43694, slope: -0.441, stopping count: 0\n",
      "Epoch: 194, train loss: 3.43470, test loss: 3.43701, slope: -0.437, stopping count: 0\n",
      "Epoch: 195, train loss: 3.43478, test loss: 3.43681, slope: -0.444, stopping count: 0\n",
      "Epoch: 196, train loss: 3.43464, test loss: 3.43694, slope: -0.441, stopping count: 0\n",
      "Epoch: 197, train loss: 3.43468, test loss: 3.43651, slope: -0.452, stopping count: 0\n",
      "Epoch: 198, train loss: 3.43466, test loss: 3.43654, slope: -0.460, stopping count: 0\n",
      "Epoch: 199, train loss: 3.43477, test loss: 3.43662, slope: -0.463, stopping count: 0\n",
      "Epoch: 200, train loss: 3.43467, test loss: 3.43643, slope: -0.473, stopping count: 0\n",
      "Epoch: 201, train loss: 3.43458, test loss: 3.43660, slope: -0.474, stopping count: 0\n",
      "Epoch: 202, train loss: 3.43486, test loss: 3.43717, slope: -0.463, stopping count: 0\n",
      "Epoch: 203, train loss: 3.43455, test loss: 3.43655, slope: -0.465, stopping count: 0\n",
      "Epoch: 204, train loss: 3.43461, test loss: 3.43668, slope: -0.467, stopping count: 0\n",
      "Epoch: 205, train loss: 3.43464, test loss: 3.43647, slope: -0.463, stopping count: 0\n",
      "Epoch: 206, train loss: 3.43458, test loss: 3.43649, slope: -0.471, stopping count: 0\n",
      "Epoch: 207, train loss: 3.43455, test loss: 3.43673, slope: -0.468, stopping count: 0\n",
      "Epoch: 208, train loss: 3.43461, test loss: 3.43639, slope: -0.470, stopping count: 0\n",
      "Epoch: 209, train loss: 3.43449, test loss: 3.43702, slope: -0.458, stopping count: 0\n",
      "Epoch: 210, train loss: 3.43443, test loss: 3.43696, slope: -0.452, stopping count: 0\n",
      "Epoch: 211, train loss: 3.43457, test loss: 3.43654, slope: -0.446, stopping count: 0\n",
      "Epoch: 212, train loss: 3.43453, test loss: 3.43630, slope: -0.440, stopping count: 0\n",
      "Epoch: 213, train loss: 3.43449, test loss: 3.43636, slope: -0.447, stopping count: 0\n",
      "Epoch: 214, train loss: 3.43444, test loss: 3.43634, slope: -0.456, stopping count: 0\n",
      "Epoch: 215, train loss: 3.43450, test loss: 3.43623, slope: -0.449, stopping count: 0\n",
      "Epoch: 216, train loss: 3.43455, test loss: 3.43657, slope: -0.451, stopping count: 0\n",
      "Epoch: 217, train loss: 3.43446, test loss: 3.43627, slope: -0.437, stopping count: 0\n",
      "Epoch: 218, train loss: 3.43445, test loss: 3.43619, slope: -0.439, stopping count: 0\n",
      "Epoch: 219, train loss: 3.43447, test loss: 3.43670, slope: -0.438, stopping count: 0\n",
      "Epoch: 220, train loss: 3.43451, test loss: 3.43640, slope: -0.443, stopping count: 0\n",
      "Epoch: 221, train loss: 3.43443, test loss: 3.43620, slope: -0.446, stopping count: 0\n",
      "Epoch: 222, train loss: 3.43436, test loss: 3.43642, slope: -0.451, stopping count: 0\n",
      "Epoch: 223, train loss: 3.43448, test loss: 3.43624, slope: -0.454, stopping count: 0\n",
      "Epoch: 224, train loss: 3.43442, test loss: 3.43635, slope: -0.459, stopping count: 0\n",
      "Epoch: 225, train loss: 3.43437, test loss: 3.43637, slope: -0.468, stopping count: 0\n",
      "Epoch: 226, train loss: 3.43441, test loss: 3.43635, slope: -0.473, stopping count: 0\n",
      "Epoch: 227, train loss: 3.43447, test loss: 3.43641, slope: -0.475, stopping count: 0\n",
      "Epoch: 228, train loss: 3.43438, test loss: 3.43635, slope: -0.480, stopping count: 0\n",
      "Epoch: 229, train loss: 3.43424, test loss: 3.43619, slope: -0.485, stopping count: 0\n",
      "Epoch: 230, train loss: 3.43428, test loss: 3.43623, slope: -0.492, stopping count: 0\n",
      "Epoch: 231, train loss: 3.43431, test loss: 3.43619, slope: -0.495, stopping count: 0\n",
      "Epoch: 232, train loss: 3.43424, test loss: 3.43620, slope: -0.502, stopping count: 0\n",
      "Epoch: 233, train loss: 3.43426, test loss: 3.43623, slope: -0.507, stopping count: 0\n",
      "Epoch: 234, train loss: 3.43436, test loss: 3.43617, slope: -0.509, stopping count: 0\n",
      "Epoch: 235, train loss: 3.43421, test loss: 3.43624, slope: -0.510, stopping count: 0\n",
      "Epoch: 236, train loss: 3.43434, test loss: 3.43607, slope: -0.498, stopping count: 0\n",
      "Epoch: 237, train loss: 3.43421, test loss: 3.43638, slope: -0.497, stopping count: 0\n",
      "Epoch: 238, train loss: 3.43428, test loss: 3.43641, slope: -0.498, stopping count: 0\n",
      "Epoch: 239, train loss: 3.43418, test loss: 3.43611, slope: -0.503, stopping count: 0\n",
      "Epoch: 240, train loss: 3.43420, test loss: 3.43710, slope: -0.489, stopping count: 0\n",
      "Epoch: 241, train loss: 3.43423, test loss: 3.43622, slope: -0.492, stopping count: 0\n",
      "Epoch: 242, train loss: 3.43415, test loss: 3.43681, slope: -0.484, stopping count: 0\n",
      "Epoch: 243, train loss: 3.43423, test loss: 3.43606, slope: -0.486, stopping count: 0\n",
      "Epoch: 244, train loss: 3.43420, test loss: 3.43612, slope: -0.493, stopping count: 0\n",
      "Epoch: 245, train loss: 3.43409, test loss: 3.43630, slope: -0.489, stopping count: 0\n",
      "Epoch: 246, train loss: 3.43413, test loss: 3.43650, slope: -0.487, stopping count: 0\n",
      "Epoch: 247, train loss: 3.43412, test loss: 3.43617, slope: -0.495, stopping count: 0\n",
      "Epoch: 248, train loss: 3.43419, test loss: 3.43596, slope: -0.484, stopping count: 0\n",
      "Epoch: 249, train loss: 3.43413, test loss: 3.43608, slope: -0.490, stopping count: 0\n",
      "Epoch: 250, train loss: 3.43419, test loss: 3.43641, slope: -0.489, stopping count: 0\n",
      "Epoch: 251, train loss: 3.43419, test loss: 3.43607, slope: -0.499, stopping count: 0\n",
      "Epoch: 252, train loss: 3.43408, test loss: 3.43619, slope: -0.502, stopping count: 0\n",
      "Epoch: 253, train loss: 3.43416, test loss: 3.43598, slope: -0.510, stopping count: 0\n",
      "Epoch: 254, train loss: 3.43414, test loss: 3.43606, slope: -0.515, stopping count: 0\n",
      "Epoch: 255, train loss: 3.43404, test loss: 3.43622, slope: -0.519, stopping count: 0\n",
      "Epoch: 256, train loss: 3.43405, test loss: 3.43620, slope: -0.522, stopping count: 0\n",
      "Epoch: 257, train loss: 3.43400, test loss: 3.43618, slope: -0.517, stopping count: 0\n",
      "Epoch: 258, train loss: 3.43413, test loss: 3.43612, slope: -0.521, stopping count: 0\n",
      "Epoch: 259, train loss: 3.43414, test loss: 3.43611, slope: -0.524, stopping count: 0\n",
      "Epoch: 260, train loss: 3.43401, test loss: 3.43593, slope: -0.523, stopping count: 0\n",
      "Epoch: 261, train loss: 3.43398, test loss: 3.43605, slope: -0.526, stopping count: 0\n",
      "Epoch: 262, train loss: 3.43399, test loss: 3.43622, slope: -0.527, stopping count: 0\n",
      "Epoch: 263, train loss: 3.43397, test loss: 3.43627, slope: -0.528, stopping count: 0\n",
      "Epoch: 264, train loss: 3.43411, test loss: 3.43628, slope: -0.527, stopping count: 0\n",
      "Epoch: 265, train loss: 3.43393, test loss: 3.43603, slope: -0.531, stopping count: 0\n",
      "Epoch: 266, train loss: 3.43393, test loss: 3.43592, slope: -0.534, stopping count: 0\n",
      "Epoch: 267, train loss: 3.43402, test loss: 3.43610, slope: -0.527, stopping count: 0\n",
      "Epoch: 268, train loss: 3.43404, test loss: 3.43590, slope: -0.527, stopping count: 0\n",
      "Epoch: 269, train loss: 3.43394, test loss: 3.43587, slope: -0.509, stopping count: 0\n",
      "Epoch: 270, train loss: 3.43392, test loss: 3.43683, slope: -0.498, stopping count: 0\n",
      "Epoch: 271, train loss: 3.43401, test loss: 3.43591, slope: -0.496, stopping count: 0\n",
      "Epoch: 272, train loss: 3.43389, test loss: 3.43670, slope: -0.488, stopping count: 0\n",
      "Epoch: 273, train loss: 3.43392, test loss: 3.43633, slope: -0.486, stopping count: 0\n",
      "Epoch: 274, train loss: 3.43394, test loss: 3.43600, slope: -0.489, stopping count: 0\n",
      "Epoch: 275, train loss: 3.43388, test loss: 3.43588, slope: -0.476, stopping count: 0\n",
      "Epoch: 276, train loss: 3.43382, test loss: 3.43614, slope: -0.477, stopping count: 0\n",
      "Epoch: 277, train loss: 3.43391, test loss: 3.43680, slope: -0.466, stopping count: 0\n",
      "Epoch: 278, train loss: 3.43389, test loss: 3.43589, slope: -0.471, stopping count: 0\n",
      "Epoch: 279, train loss: 3.43386, test loss: 3.43591, slope: -0.476, stopping count: 0\n",
      "Epoch: 280, train loss: 3.43383, test loss: 3.43573, slope: -0.458, stopping count: 0\n",
      "Epoch: 281, train loss: 3.43390, test loss: 3.43582, slope: -0.458, stopping count: 0\n",
      "Epoch: 282, train loss: 3.43377, test loss: 3.43570, slope: -0.460, stopping count: 0\n",
      "Epoch: 283, train loss: 3.43376, test loss: 3.43610, slope: -0.453, stopping count: 0\n",
      "Epoch: 284, train loss: 3.43376, test loss: 3.43591, slope: -0.457, stopping count: 0\n",
      "Epoch: 285, train loss: 3.43378, test loss: 3.43569, slope: -0.464, stopping count: 0\n",
      "Epoch: 286, train loss: 3.43376, test loss: 3.43570, slope: -0.470, stopping count: 0\n",
      "Epoch: 287, train loss: 3.43371, test loss: 3.43577, slope: -0.474, stopping count: 0\n",
      "Epoch: 288, train loss: 3.43377, test loss: 3.43571, slope: -0.480, stopping count: 0\n",
      "Epoch: 289, train loss: 3.43393, test loss: 3.43626, slope: -0.479, stopping count: 0\n",
      "Epoch: 290, train loss: 3.43371, test loss: 3.43578, slope: -0.484, stopping count: 0\n",
      "Epoch: 291, train loss: 3.43375, test loss: 3.43561, slope: -0.464, stopping count: 0\n",
      "Epoch: 292, train loss: 3.43369, test loss: 3.43574, slope: -0.469, stopping count: 0\n",
      "Epoch: 293, train loss: 3.43359, test loss: 3.43591, slope: -0.465, stopping count: 0\n",
      "Epoch: 294, train loss: 3.43359, test loss: 3.43577, slope: -0.470, stopping count: 0\n",
      "Epoch: 295, train loss: 3.43367, test loss: 3.43568, slope: -0.470, stopping count: 0\n",
      "Epoch: 296, train loss: 3.43374, test loss: 3.43633, slope: -0.465, stopping count: 0\n",
      "Epoch: 297, train loss: 3.43369, test loss: 3.43557, slope: -0.463, stopping count: 0\n",
      "Epoch: 298, train loss: 3.43365, test loss: 3.43566, slope: -0.468, stopping count: 0\n",
      "Epoch: 299, train loss: 3.43356, test loss: 3.43558, slope: -0.472, stopping count: 0\n",
      "Epoch: 300, train loss: 3.43365, test loss: 3.43632, slope: -0.467, stopping count: 0\n",
      "Epoch: 301, train loss: 3.43362, test loss: 3.43578, slope: -0.468, stopping count: 0\n",
      "Epoch: 302, train loss: 3.43368, test loss: 3.43569, slope: -0.472, stopping count: 0\n",
      "Epoch: 303, train loss: 3.43358, test loss: 3.43553, slope: -0.469, stopping count: 0\n",
      "Epoch: 304, train loss: 3.43356, test loss: 3.43559, slope: -0.475, stopping count: 0\n",
      "Epoch: 305, train loss: 3.43358, test loss: 3.43572, slope: -0.477, stopping count: 0\n",
      "Epoch: 306, train loss: 3.43357, test loss: 3.43589, slope: -0.478, stopping count: 0\n",
      "Epoch: 307, train loss: 3.43358, test loss: 3.43551, slope: -0.475, stopping count: 0\n",
      "Epoch: 308, train loss: 3.43354, test loss: 3.43573, slope: -0.478, stopping count: 0\n",
      "Epoch: 309, train loss: 3.43342, test loss: 3.43591, slope: -0.469, stopping count: 0\n",
      "Epoch: 310, train loss: 3.43351, test loss: 3.43590, slope: -0.469, stopping count: 0\n",
      "Epoch: 311, train loss: 3.43352, test loss: 3.43582, slope: -0.465, stopping count: 0\n",
      "Epoch: 312, train loss: 3.43350, test loss: 3.43658, slope: -0.456, stopping count: 0\n",
      "Epoch: 313, train loss: 3.43340, test loss: 3.43572, slope: -0.447, stopping count: 0\n",
      "Epoch: 314, train loss: 3.43340, test loss: 3.43557, slope: -0.452, stopping count: 0\n",
      "Epoch: 315, train loss: 3.43333, test loss: 3.43541, slope: -0.439, stopping count: 0\n",
      "Epoch: 316, train loss: 3.43347, test loss: 3.43548, slope: -0.445, stopping count: 0\n",
      "Epoch: 317, train loss: 3.43333, test loss: 3.43549, slope: -0.451, stopping count: 0\n",
      "Epoch: 318, train loss: 3.43334, test loss: 3.43560, slope: -0.455, stopping count: 0\n",
      "Epoch: 319, train loss: 3.43334, test loss: 3.43544, slope: -0.456, stopping count: 0\n",
      "Epoch: 320, train loss: 3.43341, test loss: 3.43548, slope: -0.461, stopping count: 0\n",
      "Epoch: 321, train loss: 3.43329, test loss: 3.43555, slope: -0.457, stopping count: 0\n",
      "Epoch: 322, train loss: 3.43330, test loss: 3.43577, slope: -0.458, stopping count: 0\n",
      "Epoch: 323, train loss: 3.43337, test loss: 3.43553, slope: -0.461, stopping count: 0\n",
      "Epoch: 324, train loss: 3.43334, test loss: 3.43541, slope: -0.466, stopping count: 0\n",
      "Epoch: 325, train loss: 3.43338, test loss: 3.43565, slope: -0.465, stopping count: 0\n",
      "Epoch: 326, train loss: 3.43337, test loss: 3.43531, slope: -0.456, stopping count: 0\n",
      "Epoch: 327, train loss: 3.43338, test loss: 3.43542, slope: -0.460, stopping count: 0\n",
      "Epoch: 328, train loss: 3.43324, test loss: 3.43525, slope: -0.457, stopping count: 0\n",
      "Epoch: 329, train loss: 3.43314, test loss: 3.43535, slope: -0.463, stopping count: 0\n",
      "Epoch: 330, train loss: 3.43332, test loss: 3.43534, slope: -0.468, stopping count: 0\n",
      "Epoch: 331, train loss: 3.43317, test loss: 3.43522, slope: -0.464, stopping count: 0\n",
      "Epoch: 332, train loss: 3.43327, test loss: 3.43602, slope: -0.461, stopping count: 0\n",
      "Epoch: 333, train loss: 3.43324, test loss: 3.43537, slope: -0.466, stopping count: 0\n",
      "Epoch: 334, train loss: 3.43317, test loss: 3.43565, slope: -0.466, stopping count: 0\n",
      "Epoch: 335, train loss: 3.43332, test loss: 3.43541, slope: -0.470, stopping count: 0\n",
      "Epoch: 336, train loss: 3.43313, test loss: 3.43522, slope: -0.476, stopping count: 0\n",
      "Epoch: 337, train loss: 3.43335, test loss: 3.43524, slope: -0.480, stopping count: 0\n",
      "Epoch: 338, train loss: 3.43319, test loss: 3.43517, slope: -0.479, stopping count: 0\n",
      "Epoch: 339, train loss: 3.43317, test loss: 3.43513, slope: -0.477, stopping count: 0\n",
      "Epoch: 340, train loss: 3.43319, test loss: 3.43534, slope: -0.480, stopping count: 0\n",
      "Epoch: 341, train loss: 3.43316, test loss: 3.43512, slope: -0.484, stopping count: 0\n",
      "Epoch: 342, train loss: 3.43303, test loss: 3.43537, slope: -0.487, stopping count: 0\n",
      "Epoch: 343, train loss: 3.43311, test loss: 3.43554, slope: -0.486, stopping count: 0\n",
      "Epoch: 344, train loss: 3.43311, test loss: 3.43526, slope: -0.490, stopping count: 0\n",
      "Epoch: 345, train loss: 3.43307, test loss: 3.43516, slope: -0.495, stopping count: 0\n",
      "Epoch: 346, train loss: 3.43306, test loss: 3.43527, slope: -0.498, stopping count: 0\n",
      "Epoch: 347, train loss: 3.43308, test loss: 3.43598, slope: -0.492, stopping count: 0\n",
      "Epoch: 348, train loss: 3.43304, test loss: 3.43523, slope: -0.496, stopping count: 0\n",
      "Epoch: 349, train loss: 3.43301, test loss: 3.43550, slope: -0.495, stopping count: 0\n",
      "Epoch: 350, train loss: 3.43303, test loss: 3.43522, slope: -0.499, stopping count: 0\n",
      "Epoch: 351, train loss: 3.43300, test loss: 3.43570, slope: -0.496, stopping count: 0\n",
      "Epoch: 352, train loss: 3.43304, test loss: 3.43570, slope: -0.494, stopping count: 0\n",
      "Epoch: 353, train loss: 3.43290, test loss: 3.43550, slope: -0.494, stopping count: 0\n",
      "Epoch: 354, train loss: 3.43297, test loss: 3.43514, slope: -0.498, stopping count: 0\n",
      "Epoch: 355, train loss: 3.43293, test loss: 3.43513, slope: -0.501, stopping count: 0\n",
      "Epoch: 356, train loss: 3.43297, test loss: 3.43526, slope: -0.504, stopping count: 0\n",
      "Epoch: 357, train loss: 3.43298, test loss: 3.43501, slope: -0.493, stopping count: 0\n",
      "Epoch: 358, train loss: 3.43296, test loss: 3.43571, slope: -0.491, stopping count: 0\n",
      "Epoch: 359, train loss: 3.43292, test loss: 3.43592, slope: -0.485, stopping count: 0\n",
      "Epoch: 360, train loss: 3.43300, test loss: 3.43528, slope: -0.487, stopping count: 0\n",
      "Epoch: 361, train loss: 3.43291, test loss: 3.43539, slope: -0.484, stopping count: 0\n",
      "Epoch: 362, train loss: 3.43285, test loss: 3.43538, slope: -0.486, stopping count: 0\n",
      "Epoch: 363, train loss: 3.43287, test loss: 3.43522, slope: -0.485, stopping count: 0\n",
      "Epoch: 364, train loss: 3.43299, test loss: 3.43518, slope: -0.488, stopping count: 0\n",
      "Epoch: 365, train loss: 3.43291, test loss: 3.43584, slope: -0.481, stopping count: 0\n",
      "Epoch: 366, train loss: 3.43282, test loss: 3.43509, slope: -0.485, stopping count: 0\n",
      "Epoch: 367, train loss: 3.43276, test loss: 3.43491, slope: -0.476, stopping count: 0\n",
      "Epoch: 368, train loss: 3.43273, test loss: 3.43499, slope: -0.481, stopping count: 0\n",
      "Epoch: 369, train loss: 3.43275, test loss: 3.43491, slope: -0.483, stopping count: 0\n",
      "Epoch: 370, train loss: 3.43278, test loss: 3.43488, slope: -0.484, stopping count: 0\n",
      "Epoch: 371, train loss: 3.43268, test loss: 3.43520, slope: -0.482, stopping count: 0\n",
      "Epoch: 372, train loss: 3.43264, test loss: 3.43515, slope: -0.484, stopping count: 0\n",
      "Epoch: 373, train loss: 3.43273, test loss: 3.43507, slope: -0.484, stopping count: 0\n",
      "Epoch: 374, train loss: 3.43283, test loss: 3.43484, slope: -0.484, stopping count: 0\n",
      "Epoch: 375, train loss: 3.43263, test loss: 3.43515, slope: -0.484, stopping count: 0\n",
      "Epoch: 376, train loss: 3.43264, test loss: 3.43493, slope: -0.488, stopping count: 0\n",
      "Epoch: 377, train loss: 3.43255, test loss: 3.43507, slope: -0.492, stopping count: 0\n",
      "Epoch: 378, train loss: 3.43271, test loss: 3.43507, slope: -0.494, stopping count: 0\n",
      "Epoch: 379, train loss: 3.43278, test loss: 3.43519, slope: -0.491, stopping count: 0\n",
      "Epoch: 380, train loss: 3.43267, test loss: 3.43553, slope: -0.490, stopping count: 0\n",
      "Epoch: 381, train loss: 3.43272, test loss: 3.43497, slope: -0.703, stopping count: 0\n",
      "Epoch: 382, train loss: 3.43264, test loss: 3.43505, slope: -0.706, stopping count: 0\n",
      "Epoch: 383, train loss: 3.43252, test loss: 3.43479, slope: -0.695, stopping count: 0\n",
      "Epoch: 384, train loss: 3.43259, test loss: 3.43508, slope: -0.698, stopping count: 0\n",
      "Epoch: 385, train loss: 3.43258, test loss: 3.43495, slope: -0.696, stopping count: 0\n",
      "Epoch: 386, train loss: 3.43263, test loss: 3.43505, slope: -0.699, stopping count: 0\n",
      "Epoch: 387, train loss: 3.43250, test loss: 3.43473, slope: -0.681, stopping count: 0\n",
      "Epoch: 388, train loss: 3.43248, test loss: 3.43471, slope: -0.684, stopping count: 0\n",
      "Epoch: 389, train loss: 3.43243, test loss: 3.43486, slope: -0.684, stopping count: 0\n",
      "Epoch: 390, train loss: 3.43266, test loss: 3.43486, slope: -0.689, stopping count: 0\n",
      "Epoch: 391, train loss: 3.43242, test loss: 3.43480, slope: -0.688, stopping count: 0\n",
      "Epoch: 392, train loss: 3.43245, test loss: 3.43571, slope: -0.682, stopping count: 0\n",
      "Epoch: 393, train loss: 3.43245, test loss: 3.43558, slope: -0.676, stopping count: 0\n",
      "Epoch: 394, train loss: 3.43239, test loss: 3.43498, slope: -0.680, stopping count: 0\n",
      "Epoch: 395, train loss: 3.43251, test loss: 3.43483, slope: -0.682, stopping count: 0\n",
      "Epoch: 396, train loss: 3.43243, test loss: 3.43472, slope: -0.689, stopping count: 0\n",
      "Epoch: 397, train loss: 3.43235, test loss: 3.43510, slope: -0.687, stopping count: 0\n",
      "Epoch: 398, train loss: 3.43240, test loss: 3.43473, slope: -0.693, stopping count: 0\n",
      "Epoch: 399, train loss: 3.43231, test loss: 3.43497, slope: -0.695, stopping count: 0\n",
      "Epoch: 400, train loss: 3.43230, test loss: 3.43478, slope: -0.700, stopping count: 0\n",
      "Epoch: 401, train loss: 3.43229, test loss: 3.43462, slope: -0.677, stopping count: 0\n",
      "Epoch: 402, train loss: 3.43228, test loss: 3.43451, slope: -0.657, stopping count: 0\n",
      "Epoch: 403, train loss: 3.43221, test loss: 3.43510, slope: -0.666, stopping count: 0\n",
      "Epoch: 404, train loss: 3.43237, test loss: 3.43450, slope: -0.671, stopping count: 0\n",
      "Epoch: 405, train loss: 3.43232, test loss: 3.43454, slope: -0.675, stopping count: 0\n",
      "Epoch: 406, train loss: 3.43221, test loss: 3.43466, slope: -0.680, stopping count: 0\n",
      "Epoch: 407, train loss: 3.43213, test loss: 3.43459, slope: -0.682, stopping count: 0\n",
      "Epoch: 408, train loss: 3.43222, test loss: 3.43458, slope: -0.688, stopping count: 0\n",
      "Epoch: 409, train loss: 3.43215, test loss: 3.43501, slope: -0.687, stopping count: 0\n",
      "Epoch: 410, train loss: 3.43218, test loss: 3.43511, slope: -0.687, stopping count: 0\n",
      "Epoch: 411, train loss: 3.43219, test loss: 3.43471, slope: -0.689, stopping count: 0\n",
      "Epoch: 412, train loss: 3.43217, test loss: 3.43452, slope: -0.695, stopping count: 0\n",
      "Epoch: 413, train loss: 3.43230, test loss: 3.43469, slope: -0.694, stopping count: 0\n",
      "Epoch: 414, train loss: 3.43211, test loss: 3.43476, slope: -0.697, stopping count: 0\n",
      "Epoch: 415, train loss: 3.43212, test loss: 3.43556, slope: -0.690, stopping count: 0\n",
      "Epoch: 416, train loss: 3.43211, test loss: 3.43447, slope: -0.689, stopping count: 0\n",
      "Epoch: 417, train loss: 3.43204, test loss: 3.43490, slope: -0.683, stopping count: 0\n",
      "Epoch: 418, train loss: 3.43203, test loss: 3.43459, slope: -0.687, stopping count: 0\n",
      "Epoch: 419, train loss: 3.43216, test loss: 3.43449, slope: -0.685, stopping count: 0\n",
      "Epoch: 420, train loss: 3.43209, test loss: 3.43505, slope: -0.685, stopping count: 0\n",
      "Epoch: 421, train loss: 3.43211, test loss: 3.43474, slope: -0.685, stopping count: 0\n",
      "Epoch: 422, train loss: 3.43210, test loss: 3.43466, slope: -0.688, stopping count: 0\n",
      "Epoch: 423, train loss: 3.43198, test loss: 3.43441, slope: -0.676, stopping count: 0\n",
      "Epoch: 424, train loss: 3.43210, test loss: 3.43445, slope: -0.682, stopping count: 0\n",
      "Epoch: 425, train loss: 3.43197, test loss: 3.43481, slope: -0.682, stopping count: 0\n",
      "Epoch: 426, train loss: 3.43200, test loss: 3.43469, slope: -0.685, stopping count: 0\n",
      "Epoch: 427, train loss: 3.43191, test loss: 3.43471, slope: -0.686, stopping count: 0\n",
      "Epoch: 428, train loss: 3.43198, test loss: 3.43455, slope: -0.690, stopping count: 0\n",
      "Epoch: 429, train loss: 3.43196, test loss: 3.43455, slope: -0.694, stopping count: 0\n",
      "Epoch: 430, train loss: 3.43197, test loss: 3.43472, slope: -0.696, stopping count: 0\n",
      "Epoch: 431, train loss: 3.43198, test loss: 3.43473, slope: -0.694, stopping count: 0\n",
      "Epoch: 432, train loss: 3.43192, test loss: 3.43459, slope: -0.697, stopping count: 0\n",
      "Epoch: 433, train loss: 3.43183, test loss: 3.43421, slope: -0.656, stopping count: 0\n",
      "Epoch: 434, train loss: 3.43204, test loss: 3.43437, slope: -0.661, stopping count: 0\n",
      "Epoch: 435, train loss: 3.43182, test loss: 3.43454, slope: -0.664, stopping count: 0\n",
      "Epoch: 436, train loss: 3.43188, test loss: 3.43459, slope: -0.667, stopping count: 0\n",
      "Epoch: 437, train loss: 3.43182, test loss: 3.43505, slope: -0.660, stopping count: 0\n",
      "Epoch: 438, train loss: 3.43186, test loss: 3.43451, slope: -0.664, stopping count: 0\n",
      "Epoch: 439, train loss: 3.43179, test loss: 3.43434, slope: -0.666, stopping count: 0\n",
      "Epoch: 440, train loss: 3.43175, test loss: 3.43448, slope: -0.670, stopping count: 0\n",
      "Epoch: 441, train loss: 3.43188, test loss: 3.43441, slope: -0.673, stopping count: 0\n",
      "Epoch: 442, train loss: 3.43183, test loss: 3.43432, slope: -0.678, stopping count: 0\n",
      "Epoch: 443, train loss: 3.43176, test loss: 3.43439, slope: -0.679, stopping count: 0\n",
      "Epoch: 444, train loss: 3.43174, test loss: 3.43443, slope: -0.683, stopping count: 0\n",
      "Epoch: 445, train loss: 3.43182, test loss: 3.43428, slope: -0.687, stopping count: 0\n",
      "Epoch: 446, train loss: 3.43177, test loss: 3.43433, slope: -0.691, stopping count: 0\n",
      "Epoch: 447, train loss: 3.43173, test loss: 3.43444, slope: -0.692, stopping count: 0\n",
      "Epoch: 448, train loss: 3.43168, test loss: 3.43430, slope: -0.696, stopping count: 0\n",
      "Epoch: 449, train loss: 3.43162, test loss: 3.43425, slope: -0.698, stopping count: 0\n",
      "Epoch: 450, train loss: 3.43164, test loss: 3.43444, slope: -0.701, stopping count: 0\n",
      "Epoch: 451, train loss: 3.43168, test loss: 3.43448, slope: -0.701, stopping count: 0\n",
      "Epoch: 452, train loss: 3.43163, test loss: 3.43511, slope: -0.698, stopping count: 0\n",
      "Epoch: 453, train loss: 3.43163, test loss: 3.43429, slope: -0.699, stopping count: 0\n",
      "Epoch: 454, train loss: 3.43152, test loss: 3.43441, slope: -0.702, stopping count: 0\n",
      "Epoch: 455, train loss: 3.43151, test loss: 3.43434, slope: -0.703, stopping count: 0\n",
      "Epoch: 456, train loss: 3.43151, test loss: 3.43419, slope: -0.701, stopping count: 0\n",
      "Epoch: 457, train loss: 3.43160, test loss: 3.43431, slope: -0.704, stopping count: 0\n",
      "Epoch: 458, train loss: 3.43150, test loss: 3.43436, slope: -0.707, stopping count: 0\n",
      "Epoch: 459, train loss: 3.43148, test loss: 3.43439, slope: -0.708, stopping count: 0\n",
      "Epoch: 460, train loss: 3.43145, test loss: 3.43422, slope: -0.712, stopping count: 0\n",
      "Epoch: 461, train loss: 3.43152, test loss: 3.43427, slope: -0.714, stopping count: 0\n",
      "Epoch: 462, train loss: 3.43147, test loss: 3.43415, slope: -0.710, stopping count: 0\n",
      "Epoch: 463, train loss: 3.43140, test loss: 3.43447, slope: -0.710, stopping count: 0\n",
      "Epoch: 464, train loss: 3.43144, test loss: 3.43442, slope: -0.712, stopping count: 0\n",
      "Epoch: 465, train loss: 3.43150, test loss: 3.43452, slope: -0.712, stopping count: 0\n",
      "Epoch: 466, train loss: 3.43149, test loss: 3.43409, slope: -0.702, stopping count: 0\n",
      "Epoch: 467, train loss: 3.43144, test loss: 3.43413, slope: -0.704, stopping count: 0\n",
      "Epoch: 468, train loss: 3.43142, test loss: 3.43416, slope: -0.708, stopping count: 0\n",
      "Epoch: 469, train loss: 3.43141, test loss: 3.43413, slope: -0.710, stopping count: 0\n",
      "Epoch: 470, train loss: 3.43151, test loss: 3.43434, slope: -0.712, stopping count: 0\n",
      "Epoch: 471, train loss: 3.43141, test loss: 3.43422, slope: -0.715, stopping count: 0\n",
      "Epoch: 472, train loss: 3.43131, test loss: 3.43434, slope: -0.717, stopping count: 0\n",
      "Epoch: 473, train loss: 3.43139, test loss: 3.43419, slope: -0.717, stopping count: 0\n",
      "Epoch: 474, train loss: 3.43129, test loss: 3.43439, slope: -0.718, stopping count: 0\n",
      "Epoch: 475, train loss: 3.43130, test loss: 3.43398, slope: -0.695, stopping count: 0\n",
      "Epoch: 476, train loss: 3.43136, test loss: 3.43418, slope: -0.697, stopping count: 0\n",
      "Epoch: 477, train loss: 3.43120, test loss: 3.43423, slope: -0.699, stopping count: 0\n",
      "Epoch: 478, train loss: 3.43128, test loss: 3.43401, slope: -0.703, stopping count: 0\n",
      "Epoch: 479, train loss: 3.43131, test loss: 3.43443, slope: -0.760, stopping count: 0\n",
      "Epoch: 480, train loss: 3.43132, test loss: 3.43390, slope: -0.742, stopping count: 0\n",
      "Epoch: 481, train loss: 3.43115, test loss: 3.43396, slope: -0.745, stopping count: 0\n",
      "Epoch: 482, train loss: 3.43123, test loss: 3.43410, slope: -0.748, stopping count: 0\n",
      "Epoch: 483, train loss: 3.43124, test loss: 3.43398, slope: -0.745, stopping count: 0\n",
      "Epoch: 484, train loss: 3.43115, test loss: 3.43418, slope: -0.747, stopping count: 0\n",
      "Epoch: 485, train loss: 3.43114, test loss: 3.43385, slope: -0.739, stopping count: 0\n",
      "Epoch: 486, train loss: 3.43114, test loss: 3.43407, slope: -0.742, stopping count: 0\n",
      "Epoch: 487, train loss: 3.43119, test loss: 3.43389, slope: -0.745, stopping count: 0\n",
      "Epoch: 488, train loss: 3.43106, test loss: 3.43411, slope: -0.747, stopping count: 0\n",
      "Epoch: 489, train loss: 3.43104, test loss: 3.43396, slope: -0.748, stopping count: 0\n",
      "Epoch: 490, train loss: 3.43111, test loss: 3.43399, slope: -0.751, stopping count: 0\n",
      "Epoch: 491, train loss: 3.43123, test loss: 3.43394, slope: -0.750, stopping count: 0\n",
      "Epoch: 492, train loss: 3.43110, test loss: 3.43403, slope: -0.753, stopping count: 0\n",
      "Epoch: 493, train loss: 3.43099, test loss: 3.43433, slope: -0.751, stopping count: 0\n",
      "Epoch: 494, train loss: 3.43098, test loss: 3.43397, slope: -0.755, stopping count: 0\n",
      "Epoch: 495, train loss: 3.43109, test loss: 3.43410, slope: -0.756, stopping count: 0\n",
      "Epoch: 496, train loss: 3.43115, test loss: 3.43433, slope: -0.757, stopping count: 0\n",
      "Epoch: 497, train loss: 3.43100, test loss: 3.43391, slope: -0.758, stopping count: 0\n",
      "Epoch: 498, train loss: 3.43107, test loss: 3.43379, slope: -0.748, stopping count: 0\n",
      "Epoch: 499, train loss: 3.43100, test loss: 3.43413, slope: -0.745, stopping count: 0\n",
      "Epoch: 500, train loss: 3.43095, test loss: 3.43385, slope: -0.749, stopping count: 0\n",
      "Epoch: 501, train loss: 3.43091, test loss: 3.43401, slope: -0.750, stopping count: 0\n",
      "Epoch: 502, train loss: 3.43105, test loss: 3.43387, slope: -0.753, stopping count: 0\n",
      "Epoch: 503, train loss: 3.43086, test loss: 3.43374, slope: -0.744, stopping count: 0\n",
      "Epoch: 504, train loss: 3.43087, test loss: 3.43392, slope: -0.747, stopping count: 0\n",
      "Epoch: 505, train loss: 3.43089, test loss: 3.43385, slope: -0.749, stopping count: 0\n",
      "Epoch: 506, train loss: 3.43079, test loss: 3.43375, slope: -0.753, stopping count: 0\n",
      "Epoch: 507, train loss: 3.43092, test loss: 3.43408, slope: -0.753, stopping count: 0\n",
      "Epoch: 508, train loss: 3.43109, test loss: 3.43389, slope: -0.756, stopping count: 0\n",
      "Epoch: 509, train loss: 3.43093, test loss: 3.43377, slope: -0.756, stopping count: 0\n",
      "Epoch: 510, train loss: 3.43079, test loss: 3.43377, slope: -0.760, stopping count: 0\n",
      "Epoch: 511, train loss: 3.43083, test loss: 3.43368, slope: -0.746, stopping count: 0\n",
      "Epoch: 512, train loss: 3.43081, test loss: 3.43373, slope: -0.750, stopping count: 0\n",
      "Epoch: 513, train loss: 3.43066, test loss: 3.43369, slope: -0.751, stopping count: 0\n",
      "Epoch: 514, train loss: 3.43086, test loss: 3.43452, slope: -0.748, stopping count: 0\n",
      "Epoch: 515, train loss: 3.43088, test loss: 3.43393, slope: -0.748, stopping count: 0\n",
      "Epoch: 516, train loss: 3.43073, test loss: 3.43366, slope: -0.746, stopping count: 0\n",
      "Epoch: 517, train loss: 3.43078, test loss: 3.43391, slope: -0.745, stopping count: 0\n",
      "Epoch: 518, train loss: 3.43072, test loss: 3.43390, slope: -0.748, stopping count: 0\n",
      "Epoch: 519, train loss: 3.43057, test loss: 3.43371, slope: -0.750, stopping count: 0\n",
      "Epoch: 520, train loss: 3.43070, test loss: 3.43386, slope: -0.752, stopping count: 0\n",
      "Epoch: 521, train loss: 3.43066, test loss: 3.43381, slope: -0.752, stopping count: 0\n",
      "Epoch: 522, train loss: 3.43066, test loss: 3.43352, slope: -0.726, stopping count: 0\n",
      "Epoch: 523, train loss: 3.43066, test loss: 3.43368, slope: -0.726, stopping count: 0\n",
      "Epoch: 524, train loss: 3.43070, test loss: 3.43345, slope: -0.714, stopping count: 0\n",
      "Epoch: 525, train loss: 3.43054, test loss: 3.43358, slope: -0.714, stopping count: 0\n",
      "Epoch: 526, train loss: 3.43070, test loss: 3.43427, slope: -0.713, stopping count: 0\n",
      "Epoch: 527, train loss: 3.43063, test loss: 3.43339, slope: -0.702, stopping count: 0\n",
      "Epoch: 528, train loss: 3.43049, test loss: 3.43351, slope: -0.706, stopping count: 0\n",
      "Epoch: 529, train loss: 3.43053, test loss: 3.43354, slope: -0.708, stopping count: 0\n",
      "Epoch: 530, train loss: 3.43056, test loss: 3.43362, slope: -0.711, stopping count: 0\n",
      "Epoch: 531, train loss: 3.43052, test loss: 3.43387, slope: -0.710, stopping count: 0\n",
      "Epoch: 532, train loss: 3.43051, test loss: 3.43355, slope: -0.714, stopping count: 0\n",
      "Epoch: 533, train loss: 3.43045, test loss: 3.43357, slope: -0.714, stopping count: 0\n",
      "Epoch: 534, train loss: 3.43042, test loss: 3.43359, slope: -0.717, stopping count: 0\n",
      "Epoch: 535, train loss: 3.43049, test loss: 3.43339, slope: -0.719, stopping count: 0\n",
      "Epoch: 536, train loss: 3.43060, test loss: 3.43339, slope: -0.723, stopping count: 0\n",
      "Epoch: 537, train loss: 3.43049, test loss: 3.43356, slope: -0.724, stopping count: 0\n",
      "Epoch: 538, train loss: 3.43038, test loss: 3.43336, slope: -0.723, stopping count: 0\n",
      "Epoch: 539, train loss: 3.43042, test loss: 3.43356, slope: -0.727, stopping count: 0\n",
      "Epoch: 540, train loss: 3.43049, test loss: 3.43371, slope: -0.728, stopping count: 0\n",
      "Epoch: 541, train loss: 3.43045, test loss: 3.43350, slope: -0.730, stopping count: 0\n",
      "Epoch: 542, train loss: 3.43036, test loss: 3.43382, slope: -0.730, stopping count: 0\n",
      "Epoch: 543, train loss: 3.43047, test loss: 3.43357, slope: -0.726, stopping count: 0\n",
      "Epoch: 544, train loss: 3.43043, test loss: 3.43400, slope: -0.726, stopping count: 0\n",
      "Epoch: 545, train loss: 3.43026, test loss: 3.43330, slope: -0.712, stopping count: 0\n",
      "Epoch: 546, train loss: 3.43048, test loss: 3.43333, slope: -0.716, stopping count: 0\n",
      "Epoch: 547, train loss: 3.43024, test loss: 3.43376, slope: -0.715, stopping count: 0\n",
      "Epoch: 548, train loss: 3.43034, test loss: 3.43339, slope: -0.718, stopping count: 0\n",
      "Epoch: 549, train loss: 3.43040, test loss: 3.43353, slope: -0.718, stopping count: 0\n",
      "Epoch: 550, train loss: 3.43030, test loss: 3.43328, slope: -0.718, stopping count: 0\n",
      "Epoch: 551, train loss: 3.43027, test loss: 3.43339, slope: -0.718, stopping count: 0\n",
      "Epoch: 552, train loss: 3.43024, test loss: 3.43336, slope: -0.721, stopping count: 0\n",
      "Epoch: 553, train loss: 3.43037, test loss: 3.43325, slope: -0.757, stopping count: 0\n",
      "Epoch: 554, train loss: 3.43025, test loss: 3.43360, slope: -0.759, stopping count: 0\n",
      "Epoch: 555, train loss: 3.43018, test loss: 3.43340, slope: -0.760, stopping count: 0\n",
      "Epoch: 556, train loss: 3.43022, test loss: 3.43317, slope: -0.746, stopping count: 0\n",
      "Epoch: 557, train loss: 3.43015, test loss: 3.43334, slope: -0.747, stopping count: 0\n",
      "Epoch: 558, train loss: 3.43015, test loss: 3.43352, slope: -0.748, stopping count: 0\n",
      "Epoch: 559, train loss: 3.43032, test loss: 3.43356, slope: -0.749, stopping count: 0\n",
      "Epoch: 560, train loss: 3.43021, test loss: 3.43332, slope: -0.752, stopping count: 0\n",
      "Epoch: 561, train loss: 3.43022, test loss: 3.43330, slope: -0.753, stopping count: 0\n",
      "Epoch: 562, train loss: 3.43003, test loss: 3.43348, slope: -0.755, stopping count: 0\n",
      "Epoch: 563, train loss: 3.43009, test loss: 3.43328, slope: -0.757, stopping count: 0\n",
      "Epoch: 564, train loss: 3.43007, test loss: 3.43341, slope: -0.760, stopping count: 0\n",
      "Epoch: 565, train loss: 3.43007, test loss: 3.43314, slope: -0.755, stopping count: 0\n",
      "Epoch: 566, train loss: 3.43013, test loss: 3.43331, slope: -0.757, stopping count: 0\n",
      "Epoch: 567, train loss: 3.43024, test loss: 3.43323, slope: -0.758, stopping count: 0\n",
      "Epoch: 568, train loss: 3.43005, test loss: 3.43311, slope: -0.754, stopping count: 0\n",
      "Epoch: 569, train loss: 3.43011, test loss: 3.43310, slope: -0.756, stopping count: 0\n",
      "Epoch: 570, train loss: 3.43001, test loss: 3.43335, slope: -0.758, stopping count: 0\n",
      "Epoch: 571, train loss: 3.43009, test loss: 3.43315, slope: -0.760, stopping count: 0\n",
      "Epoch: 572, train loss: 3.43008, test loss: 3.43325, slope: -0.763, stopping count: 0\n",
      "Epoch: 573, train loss: 3.42999, test loss: 3.43325, slope: -0.764, stopping count: 0\n",
      "Epoch: 574, train loss: 3.43006, test loss: 3.43391, slope: -0.762, stopping count: 0\n",
      "Epoch: 575, train loss: 3.43017, test loss: 3.43326, slope: -0.763, stopping count: 0\n",
      "Epoch: 576, train loss: 3.43006, test loss: 3.43311, slope: -0.767, stopping count: 0\n",
      "Epoch: 577, train loss: 3.42998, test loss: 3.43378, slope: -0.761, stopping count: 0\n",
      "Epoch: 578, train loss: 3.42991, test loss: 3.43330, slope: -0.763, stopping count: 0\n",
      "Epoch: 579, train loss: 3.43001, test loss: 3.43308, slope: -0.758, stopping count: 0\n",
      "Epoch: 580, train loss: 3.43008, test loss: 3.43313, slope: -0.761, stopping count: 0\n",
      "Epoch: 581, train loss: 3.42984, test loss: 3.43331, slope: -0.762, stopping count: 0\n",
      "Epoch: 582, train loss: 3.43010, test loss: 3.43315, slope: -0.765, stopping count: 0\n",
      "Epoch: 583, train loss: 3.42997, test loss: 3.43312, slope: -0.766, stopping count: 0\n",
      "Epoch: 584, train loss: 3.42990, test loss: 3.43315, slope: -0.769, stopping count: 0\n",
      "Epoch: 585, train loss: 3.42984, test loss: 3.43313, slope: -0.768, stopping count: 0\n",
      "Epoch: 586, train loss: 3.42988, test loss: 3.43321, slope: -0.771, stopping count: 0\n",
      "Epoch: 587, train loss: 3.42989, test loss: 3.43359, slope: -0.768, stopping count: 0\n",
      "Epoch: 588, train loss: 3.42996, test loss: 3.43295, slope: -0.745, stopping count: 0\n",
      "Epoch: 589, train loss: 3.42983, test loss: 3.43354, slope: -0.743, stopping count: 0\n",
      "Epoch: 590, train loss: 3.42989, test loss: 3.43298, slope: -0.747, stopping count: 0\n",
      "Epoch: 591, train loss: 3.42984, test loss: 3.43398, slope: -0.739, stopping count: 0\n",
      "Epoch: 592, train loss: 3.42983, test loss: 3.43310, slope: -0.742, stopping count: 0\n",
      "Epoch: 593, train loss: 3.42979, test loss: 3.43333, slope: -0.742, stopping count: 0\n",
      "Epoch: 594, train loss: 3.42978, test loss: 3.43318, slope: -0.744, stopping count: 0\n",
      "Epoch: 595, train loss: 3.42973, test loss: 3.43301, slope: -0.745, stopping count: 0\n",
      "Epoch: 596, train loss: 3.42983, test loss: 3.43307, slope: -0.747, stopping count: 0\n",
      "Epoch: 597, train loss: 3.42967, test loss: 3.43317, slope: -0.748, stopping count: 0\n",
      "Epoch: 598, train loss: 3.42985, test loss: 3.43385, slope: -0.746, stopping count: 0\n",
      "Epoch: 599, train loss: 3.42979, test loss: 3.43319, slope: -0.742, stopping count: 0\n",
      "Epoch: 600, train loss: 3.42976, test loss: 3.43294, slope: -0.745, stopping count: 0\n",
      "Epoch: 601, train loss: 3.42968, test loss: 3.43328, slope: -0.743, stopping count: 0\n",
      "Epoch: 602, train loss: 3.42963, test loss: 3.43303, slope: -0.746, stopping count: 0\n",
      "Epoch: 603, train loss: 3.42964, test loss: 3.43283, slope: -0.724, stopping count: 0\n",
      "Epoch: 604, train loss: 3.42984, test loss: 3.43340, slope: -0.725, stopping count: 0\n",
      "Epoch: 605, train loss: 3.42965, test loss: 3.43279, slope: -0.719, stopping count: 0\n",
      "Epoch: 606, train loss: 3.42969, test loss: 3.43277, slope: -0.720, stopping count: 0\n",
      "Epoch: 607, train loss: 3.42970, test loss: 3.43355, slope: -0.718, stopping count: 0\n",
      "Epoch: 608, train loss: 3.42957, test loss: 3.43302, slope: -0.720, stopping count: 0\n",
      "Epoch: 609, train loss: 3.42984, test loss: 3.43308, slope: -0.719, stopping count: 0\n",
      "Epoch: 610, train loss: 3.42961, test loss: 3.43291, slope: -0.722, stopping count: 0\n",
      "Epoch: 611, train loss: 3.42967, test loss: 3.43282, slope: -0.722, stopping count: 0\n",
      "Epoch: 612, train loss: 3.42953, test loss: 3.43283, slope: -0.725, stopping count: 0\n",
      "Epoch: 613, train loss: 3.42960, test loss: 3.43294, slope: -0.726, stopping count: 0\n",
      "Epoch: 614, train loss: 3.42954, test loss: 3.43316, slope: -0.727, stopping count: 0\n",
      "Epoch: 615, train loss: 3.42950, test loss: 3.43288, slope: -0.727, stopping count: 0\n",
      "Epoch: 616, train loss: 3.42955, test loss: 3.43298, slope: -0.729, stopping count: 0\n",
      "Epoch: 617, train loss: 3.42954, test loss: 3.43283, slope: -0.728, stopping count: 0\n",
      "Epoch: 618, train loss: 3.42960, test loss: 3.43274, slope: -0.724, stopping count: 0\n",
      "Epoch: 619, train loss: 3.42957, test loss: 3.43288, slope: -0.723, stopping count: 0\n",
      "Epoch: 620, train loss: 3.42952, test loss: 3.43337, slope: -0.723, stopping count: 0\n",
      "Epoch: 621, train loss: 3.42946, test loss: 3.43271, slope: -0.717, stopping count: 0\n",
      "Epoch: 622, train loss: 3.42949, test loss: 3.43282, slope: -0.720, stopping count: 0\n",
      "Epoch: 623, train loss: 3.42968, test loss: 3.43295, slope: -0.837, stopping count: 0\n",
      "Epoch: 624, train loss: 3.42961, test loss: 3.43336, slope: -0.836, stopping count: 0\n",
      "Epoch: 625, train loss: 3.42966, test loss: 3.43293, slope: -0.835, stopping count: 0\n",
      "Epoch: 626, train loss: 3.42946, test loss: 3.43343, slope: -0.835, stopping count: 0\n",
      "Epoch: 627, train loss: 3.42947, test loss: 3.43319, slope: -0.833, stopping count: 0\n",
      "Epoch: 628, train loss: 3.42953, test loss: 3.43265, slope: -0.823, stopping count: 0\n",
      "Epoch: 629, train loss: 3.42934, test loss: 3.43287, slope: -0.824, stopping count: 0\n",
      "Epoch: 630, train loss: 3.42939, test loss: 3.43280, slope: -0.827, stopping count: 0\n",
      "Epoch: 631, train loss: 3.42947, test loss: 3.43291, slope: -0.827, stopping count: 0\n",
      "Epoch: 632, train loss: 3.42952, test loss: 3.43263, slope: -0.824, stopping count: 0\n",
      "Epoch: 633, train loss: 3.42943, test loss: 3.43338, slope: -0.821, stopping count: 0\n",
      "Epoch: 634, train loss: 3.42940, test loss: 3.43332, slope: -0.821, stopping count: 0\n",
      "Epoch: 635, train loss: 3.42940, test loss: 3.43265, slope: -0.822, stopping count: 0\n",
      "Epoch: 636, train loss: 3.42929, test loss: 3.43301, slope: -0.823, stopping count: 0\n",
      "Epoch: 637, train loss: 3.42930, test loss: 3.43280, slope: -0.824, stopping count: 0\n",
      "Epoch: 638, train loss: 3.42935, test loss: 3.43293, slope: -0.825, stopping count: 0\n",
      "Epoch: 639, train loss: 3.42927, test loss: 3.43275, slope: -0.826, stopping count: 0\n",
      "Epoch: 640, train loss: 3.42956, test loss: 3.43289, slope: -0.827, stopping count: 0\n",
      "Epoch: 641, train loss: 3.42934, test loss: 3.43280, slope: -0.827, stopping count: 0\n",
      "Epoch: 642, train loss: 3.42934, test loss: 3.43267, slope: -0.830, stopping count: 0\n",
      "Epoch: 643, train loss: 3.42926, test loss: 3.43257, slope: -0.817, stopping count: 0\n",
      "Epoch: 644, train loss: 3.42928, test loss: 3.43310, slope: -0.817, stopping count: 0\n",
      "Epoch: 645, train loss: 3.42935, test loss: 3.43262, slope: -0.817, stopping count: 0\n",
      "Epoch: 646, train loss: 3.42932, test loss: 3.43360, slope: -0.815, stopping count: 0\n",
      "Epoch: 647, train loss: 3.42925, test loss: 3.43262, slope: -0.816, stopping count: 0\n",
      "Epoch: 648, train loss: 3.42918, test loss: 3.43274, slope: -0.818, stopping count: 0\n",
      "Epoch: 649, train loss: 3.42914, test loss: 3.43282, slope: -0.817, stopping count: 0\n",
      "Epoch: 650, train loss: 3.42923, test loss: 3.43253, slope: -0.810, stopping count: 0\n",
      "Epoch: 651, train loss: 3.42913, test loss: 3.43264, slope: -0.811, stopping count: 0\n",
      "Epoch: 652, train loss: 3.42916, test loss: 3.43271, slope: -0.813, stopping count: 0\n",
      "Epoch: 653, train loss: 3.42906, test loss: 3.43261, slope: -0.814, stopping count: 0\n",
      "Epoch: 654, train loss: 3.42909, test loss: 3.43316, slope: -0.814, stopping count: 0\n",
      "Epoch: 655, train loss: 3.42938, test loss: 3.43255, slope: -0.815, stopping count: 0\n",
      "Epoch: 656, train loss: 3.42918, test loss: 3.43278, slope: -0.817, stopping count: 0\n",
      "Epoch: 657, train loss: 3.42912, test loss: 3.43275, slope: -0.817, stopping count: 0\n",
      "Epoch: 658, train loss: 3.42928, test loss: 3.43278, slope: -0.818, stopping count: 0\n",
      "Epoch: 659, train loss: 3.42915, test loss: 3.43255, slope: -0.819, stopping count: 0\n",
      "Epoch: 660, train loss: 3.42922, test loss: 3.43250, slope: -0.815, stopping count: 0\n",
      "Epoch: 661, train loss: 3.42907, test loss: 3.43262, slope: -0.816, stopping count: 0\n",
      "Epoch: 662, train loss: 3.42904, test loss: 3.43255, slope: -0.819, stopping count: 0\n",
      "Epoch: 663, train loss: 3.42901, test loss: 3.43342, slope: -0.820, stopping count: 0\n",
      "Epoch: 664, train loss: 3.42908, test loss: 3.43252, slope: -0.822, stopping count: 0\n",
      "Epoch: 665, train loss: 3.42909, test loss: 3.43256, slope: -0.823, stopping count: 0\n",
      "Epoch: 666, train loss: 3.42890, test loss: 3.43259, slope: -0.825, stopping count: 0\n",
      "Epoch: 667, train loss: 3.42917, test loss: 3.43311, slope: -0.821, stopping count: 0\n",
      "Epoch: 668, train loss: 3.42910, test loss: 3.43260, slope: -0.823, stopping count: 0\n",
      "Epoch: 669, train loss: 3.42892, test loss: 3.43272, slope: -0.822, stopping count: 0\n",
      "Epoch: 670, train loss: 3.42898, test loss: 3.43266, slope: -0.824, stopping count: 0\n",
      "Epoch: 671, train loss: 3.42899, test loss: 3.43265, slope: -0.824, stopping count: 0\n",
      "Epoch: 672, train loss: 3.42905, test loss: 3.43254, slope: -0.826, stopping count: 0\n",
      "Epoch: 673, train loss: 3.42896, test loss: 3.43296, slope: -0.825, stopping count: 0\n",
      "Epoch: 674, train loss: 3.42899, test loss: 3.43252, slope: -0.827, stopping count: 0\n",
      "Epoch: 675, train loss: 3.42899, test loss: 3.43326, slope: -0.824, stopping count: 0\n",
      "Epoch: 676, train loss: 3.42904, test loss: 3.43246, slope: -0.817, stopping count: 0\n",
      "Epoch: 677, train loss: 3.42894, test loss: 3.43250, slope: -0.818, stopping count: 0\n",
      "Epoch: 678, train loss: 3.42895, test loss: 3.43236, slope: -0.798, stopping count: 0\n",
      "Epoch: 679, train loss: 3.42894, test loss: 3.43274, slope: -0.796, stopping count: 0\n",
      "Epoch: 680, train loss: 3.42891, test loss: 3.43247, slope: -0.799, stopping count: 0\n",
      "Epoch: 681, train loss: 3.42884, test loss: 3.43255, slope: -0.799, stopping count: 0\n",
      "Epoch: 682, train loss: 3.42889, test loss: 3.43248, slope: -0.801, stopping count: 0\n",
      "Epoch: 683, train loss: 3.42894, test loss: 3.43259, slope: -0.800, stopping count: 0\n",
      "Epoch: 684, train loss: 3.42881, test loss: 3.43259, slope: -0.802, stopping count: 0\n",
      "Epoch: 685, train loss: 3.42893, test loss: 3.43286, slope: -0.799, stopping count: 0\n",
      "Epoch: 686, train loss: 3.42902, test loss: 3.43233, slope: -0.795, stopping count: 0\n",
      "Epoch: 687, train loss: 3.42887, test loss: 3.43232, slope: -0.795, stopping count: 0\n",
      "Epoch: 688, train loss: 3.42895, test loss: 3.43237, slope: -0.797, stopping count: 0\n",
      "Epoch: 689, train loss: 3.42883, test loss: 3.43262, slope: -0.797, stopping count: 0\n",
      "Epoch: 690, train loss: 3.42884, test loss: 3.43249, slope: -0.799, stopping count: 0\n",
      "Epoch: 691, train loss: 3.42912, test loss: 3.43252, slope: -0.798, stopping count: 0\n",
      "Epoch: 692, train loss: 3.42878, test loss: 3.43253, slope: -0.800, stopping count: 0\n",
      "Epoch: 693, train loss: 3.42874, test loss: 3.43241, slope: -0.809, stopping count: 0\n",
      "Epoch: 694, train loss: 3.42875, test loss: 3.43245, slope: -0.811, stopping count: 0\n",
      "Epoch: 695, train loss: 3.42874, test loss: 3.43241, slope: -0.811, stopping count: 0\n",
      "Epoch: 696, train loss: 3.42874, test loss: 3.43257, slope: -0.812, stopping count: 0\n",
      "Epoch: 697, train loss: 3.42886, test loss: 3.43236, slope: -0.811, stopping count: 0\n",
      "Epoch: 698, train loss: 3.42874, test loss: 3.43280, slope: -0.811, stopping count: 0\n",
      "Epoch: 699, train loss: 3.42872, test loss: 3.43255, slope: -0.810, stopping count: 0\n",
      "Epoch: 700, train loss: 3.42866, test loss: 3.43237, slope: -0.812, stopping count: 0\n",
      "Epoch: 701, train loss: 3.42881, test loss: 3.43243, slope: -0.809, stopping count: 0\n",
      "Epoch: 702, train loss: 3.42870, test loss: 3.43242, slope: -0.811, stopping count: 0\n",
      "Epoch: 703, train loss: 3.42876, test loss: 3.43255, slope: -0.808, stopping count: 0\n",
      "Epoch: 704, train loss: 3.42880, test loss: 3.43252, slope: -0.809, stopping count: 0\n",
      "Epoch: 705, train loss: 3.42859, test loss: 3.43244, slope: -0.807, stopping count: 0\n",
      "Epoch: 706, train loss: 3.42863, test loss: 3.43222, slope: -0.788, stopping count: 0\n",
      "Epoch: 707, train loss: 3.42868, test loss: 3.43233, slope: -0.788, stopping count: 0\n",
      "Epoch: 708, train loss: 3.42858, test loss: 3.43227, slope: -0.790, stopping count: 0\n",
      "Epoch: 709, train loss: 3.42872, test loss: 3.43285, slope: -0.788, stopping count: 0\n",
      "Epoch: 710, train loss: 3.42858, test loss: 3.43236, slope: -0.790, stopping count: 0\n",
      "Epoch: 711, train loss: 3.42857, test loss: 3.43224, slope: -0.789, stopping count: 0\n",
      "Epoch: 712, train loss: 3.42860, test loss: 3.43301, slope: -0.788, stopping count: 0\n",
      "Epoch: 713, train loss: 3.42865, test loss: 3.43256, slope: -0.787, stopping count: 0\n",
      "Epoch: 714, train loss: 3.42869, test loss: 3.43237, slope: -0.789, stopping count: 0\n",
      "Epoch: 715, train loss: 3.42857, test loss: 3.43244, slope: -0.786, stopping count: 0\n",
      "Epoch: 716, train loss: 3.42851, test loss: 3.43265, slope: -0.786, stopping count: 0\n",
      "Epoch: 717, train loss: 3.42852, test loss: 3.43252, slope: -0.798, stopping count: 0\n",
      "Epoch: 718, train loss: 3.42867, test loss: 3.43226, slope: -0.800, stopping count: 0\n",
      "Epoch: 719, train loss: 3.42852, test loss: 3.43222, slope: -0.798, stopping count: 0\n",
      "Epoch: 720, train loss: 3.42863, test loss: 3.43231, slope: -0.800, stopping count: 0\n",
      "Epoch: 721, train loss: 3.42858, test loss: 3.43226, slope: -0.799, stopping count: 0\n",
      "Epoch: 722, train loss: 3.42863, test loss: 3.43241, slope: -0.800, stopping count: 0\n",
      "Epoch: 723, train loss: 3.42847, test loss: 3.43231, slope: -0.798, stopping count: 0\n",
      "Epoch: 724, train loss: 3.42848, test loss: 3.43220, slope: -0.796, stopping count: 0\n",
      "Epoch: 725, train loss: 3.42846, test loss: 3.43237, slope: -0.794, stopping count: 0\n",
      "Epoch: 726, train loss: 3.42850, test loss: 3.43225, slope: -0.796, stopping count: 0\n",
      "Epoch: 727, train loss: 3.42862, test loss: 3.43277, slope: -0.793, stopping count: 0\n",
      "Epoch: 728, train loss: 3.42851, test loss: 3.43208, slope: -0.769, stopping count: 0\n",
      "Epoch: 729, train loss: 3.42850, test loss: 3.43241, slope: -0.792, stopping count: 0\n",
      "Epoch: 730, train loss: 3.42837, test loss: 3.43222, slope: -0.794, stopping count: 0\n",
      "Epoch: 731, train loss: 3.42849, test loss: 3.43226, slope: -0.794, stopping count: 0\n",
      "Epoch: 732, train loss: 3.42850, test loss: 3.43233, slope: -0.795, stopping count: 0\n",
      "Epoch: 733, train loss: 3.42849, test loss: 3.43243, slope: -0.794, stopping count: 0\n",
      "Epoch: 734, train loss: 3.42843, test loss: 3.43259, slope: -0.794, stopping count: 0\n",
      "Epoch: 735, train loss: 3.42848, test loss: 3.43234, slope: -0.793, stopping count: 0\n",
      "Epoch: 736, train loss: 3.42843, test loss: 3.43239, slope: -0.794, stopping count: 0\n",
      "Epoch: 737, train loss: 3.42843, test loss: 3.43216, slope: -0.795, stopping count: 0\n",
      "Epoch: 738, train loss: 3.42847, test loss: 3.43218, slope: -0.797, stopping count: 0\n",
      "Epoch: 739, train loss: 3.42837, test loss: 3.43213, slope: -0.797, stopping count: 0\n",
      "Epoch: 740, train loss: 3.42839, test loss: 3.43212, slope: -0.799, stopping count: 0\n",
      "Epoch: 741, train loss: 3.42848, test loss: 3.43235, slope: -0.797, stopping count: 0\n",
      "Epoch: 742, train loss: 3.42842, test loss: 3.43244, slope: -0.798, stopping count: 0\n",
      "Epoch: 743, train loss: 3.42840, test loss: 3.43217, slope: -0.796, stopping count: 0\n",
      "Epoch: 744, train loss: 3.42828, test loss: 3.43207, slope: -0.797, stopping count: 0\n",
      "Epoch: 745, train loss: 3.42831, test loss: 3.43215, slope: -0.796, stopping count: 0\n",
      "Epoch: 746, train loss: 3.42831, test loss: 3.43219, slope: -0.798, stopping count: 0\n",
      "Epoch: 747, train loss: 3.42822, test loss: 3.43214, slope: -0.798, stopping count: 0\n",
      "Epoch: 748, train loss: 3.42817, test loss: 3.43230, slope: -0.799, stopping count: 0\n",
      "Epoch: 749, train loss: 3.42824, test loss: 3.43260, slope: -0.796, stopping count: 0\n",
      "Epoch: 750, train loss: 3.42822, test loss: 3.43215, slope: -0.798, stopping count: 0\n",
      "Epoch: 751, train loss: 3.42843, test loss: 3.43207, slope: -0.797, stopping count: 0\n",
      "Epoch: 752, train loss: 3.42824, test loss: 3.43208, slope: -0.799, stopping count: 0\n",
      "Epoch: 753, train loss: 3.42837, test loss: 3.43210, slope: -0.798, stopping count: 0\n",
      "Epoch: 754, train loss: 3.42827, test loss: 3.43258, slope: -0.798, stopping count: 0\n",
      "Epoch: 755, train loss: 3.42827, test loss: 3.43234, slope: -0.796, stopping count: 0\n",
      "Epoch: 756, train loss: 3.42838, test loss: 3.43290, slope: -0.794, stopping count: 0\n",
      "Epoch: 757, train loss: 3.42828, test loss: 3.43216, slope: -0.792, stopping count: 0\n",
      "Epoch: 758, train loss: 3.42828, test loss: 3.43231, slope: -0.793, stopping count: 0\n",
      "Epoch: 759, train loss: 3.42817, test loss: 3.43253, slope: -0.788, stopping count: 0\n",
      "Epoch: 760, train loss: 3.42813, test loss: 3.43203, slope: -0.781, stopping count: 0\n",
      "Epoch: 761, train loss: 3.42814, test loss: 3.43245, slope: -0.778, stopping count: 0\n",
      "Epoch: 762, train loss: 3.42817, test loss: 3.43240, slope: -0.779, stopping count: 0\n",
      "Epoch: 763, train loss: 3.42830, test loss: 3.43196, slope: -0.764, stopping count: 0\n",
      "Epoch: 764, train loss: 3.42830, test loss: 3.43213, slope: -0.765, stopping count: 0\n",
      "Epoch: 765, train loss: 3.42830, test loss: 3.43189, slope: -0.751, stopping count: 0\n",
      "Epoch: 766, train loss: 3.42830, test loss: 3.43197, slope: -0.753, stopping count: 0\n",
      "Epoch: 767, train loss: 3.42804, test loss: 3.43210, slope: -0.752, stopping count: 0\n",
      "Epoch: 768, train loss: 3.42812, test loss: 3.43205, slope: -0.753, stopping count: 0\n",
      "Epoch: 769, train loss: 3.42805, test loss: 3.43200, slope: -0.753, stopping count: 0\n",
      "Epoch: 770, train loss: 3.42810, test loss: 3.43207, slope: -0.754, stopping count: 0\n",
      "Epoch: 771, train loss: 3.42819, test loss: 3.43200, slope: -0.753, stopping count: 0\n",
      "Epoch: 772, train loss: 3.42803, test loss: 3.43210, slope: -0.754, stopping count: 0\n",
      "Epoch: 773, train loss: 3.42803, test loss: 3.43216, slope: -0.754, stopping count: 0\n",
      "Epoch: 774, train loss: 3.42813, test loss: 3.43238, slope: -0.754, stopping count: 0\n",
      "Epoch: 775, train loss: 3.42806, test loss: 3.43217, slope: -0.753, stopping count: 0\n",
      "Epoch: 776, train loss: 3.42807, test loss: 3.43198, slope: -0.755, stopping count: 0\n",
      "Epoch: 777, train loss: 3.42833, test loss: 3.43186, slope: -0.750, stopping count: 0\n",
      "Epoch: 778, train loss: 3.42811, test loss: 3.43202, slope: -0.751, stopping count: 0\n",
      "Epoch: 779, train loss: 3.42808, test loss: 3.43220, slope: -0.750, stopping count: 0\n",
      "Epoch: 780, train loss: 3.42804, test loss: 3.43206, slope: -0.751, stopping count: 0\n",
      "Epoch: 781, train loss: 3.42797, test loss: 3.43191, slope: -0.751, stopping count: 0\n",
      "Epoch: 782, train loss: 3.42790, test loss: 3.43187, slope: -0.753, stopping count: 0\n",
      "Epoch: 783, train loss: 3.42799, test loss: 3.43199, slope: -0.775, stopping count: 0\n",
      "Epoch: 784, train loss: 3.42807, test loss: 3.43238, slope: -0.775, stopping count: 0\n",
      "Epoch: 785, train loss: 3.42793, test loss: 3.43191, slope: -0.776, stopping count: 0\n",
      "Epoch: 786, train loss: 3.42804, test loss: 3.43229, slope: -0.776, stopping count: 0\n",
      "Epoch: 787, train loss: 3.42796, test loss: 3.43181, slope: -0.764, stopping count: 0\n",
      "Epoch: 788, train loss: 3.42788, test loss: 3.43215, slope: -0.765, stopping count: 0\n",
      "Epoch: 789, train loss: 3.42786, test loss: 3.43218, slope: -0.763, stopping count: 0\n",
      "Epoch: 790, train loss: 3.42810, test loss: 3.43182, slope: -0.765, stopping count: 0\n",
      "Epoch: 791, train loss: 3.42785, test loss: 3.43192, slope: -0.765, stopping count: 0\n",
      "Epoch: 792, train loss: 3.42797, test loss: 3.43201, slope: -0.766, stopping count: 0\n",
      "Epoch: 793, train loss: 3.42785, test loss: 3.43191, slope: -0.764, stopping count: 0\n",
      "Epoch: 794, train loss: 3.42793, test loss: 3.43211, slope: -0.765, stopping count: 0\n",
      "Epoch: 795, train loss: 3.42799, test loss: 3.43181, slope: -0.764, stopping count: 0\n",
      "Epoch: 796, train loss: 3.42789, test loss: 3.43198, slope: -0.766, stopping count: 0\n",
      "Epoch: 797, train loss: 3.42790, test loss: 3.43191, slope: -0.764, stopping count: 0\n",
      "Epoch: 798, train loss: 3.42796, test loss: 3.43196, slope: -0.765, stopping count: 0\n",
      "Epoch: 799, train loss: 3.42799, test loss: 3.43182, slope: -0.765, stopping count: 0\n",
      "Epoch: 800, train loss: 3.42775, test loss: 3.43190, slope: -0.766, stopping count: 0\n",
      "Epoch: 801, train loss: 3.42779, test loss: 3.43190, slope: -0.766, stopping count: 0\n",
      "Epoch: 802, train loss: 3.42778, test loss: 3.43217, slope: -0.766, stopping count: 0\n",
      "Epoch: 803, train loss: 3.42780, test loss: 3.43185, slope: -0.766, stopping count: 0\n",
      "Epoch: 804, train loss: 3.42774, test loss: 3.43247, slope: -0.766, stopping count: 0\n",
      "Epoch: 805, train loss: 3.42818, test loss: 3.43221, slope: -0.762, stopping count: 0\n",
      "Epoch: 806, train loss: 3.42786, test loss: 3.43265, slope: -0.760, stopping count: 0\n",
      "Epoch: 807, train loss: 3.42783, test loss: 3.43184, slope: -0.761, stopping count: 0\n",
      "Epoch: 808, train loss: 3.42796, test loss: 3.43201, slope: -0.761, stopping count: 0\n",
      "Epoch: 809, train loss: 3.42768, test loss: 3.43218, slope: -0.760, stopping count: 0\n",
      "Epoch: 810, train loss: 3.42776, test loss: 3.43184, slope: -0.762, stopping count: 0\n",
      "Epoch: 811, train loss: 3.42773, test loss: 3.43179, slope: -0.758, stopping count: 0\n",
      "Epoch: 812, train loss: 3.42770, test loss: 3.43192, slope: -0.759, stopping count: 0\n",
      "Epoch: 813, train loss: 3.42787, test loss: 3.43168, slope: -0.738, stopping count: 0\n",
      "Epoch: 814, train loss: 3.42778, test loss: 3.43247, slope: -0.737, stopping count: 0\n",
      "Epoch: 815, train loss: 3.42789, test loss: 3.43184, slope: -0.737, stopping count: 0\n",
      "Epoch: 816, train loss: 3.42764, test loss: 3.43167, slope: -0.736, stopping count: 0\n",
      "Epoch: 817, train loss: 3.42759, test loss: 3.43196, slope: -0.734, stopping count: 0\n",
      "Epoch: 818, train loss: 3.42778, test loss: 3.43198, slope: -0.734, stopping count: 0\n",
      "Epoch: 819, train loss: 3.42771, test loss: 3.43183, slope: -0.732, stopping count: 0\n",
      "Epoch: 820, train loss: 3.42758, test loss: 3.43169, slope: -0.734, stopping count: 0\n",
      "Epoch: 821, train loss: 3.42763, test loss: 3.43198, slope: -0.732, stopping count: 0\n",
      "Epoch: 822, train loss: 3.42765, test loss: 3.43173, slope: -0.734, stopping count: 0\n",
      "Epoch: 823, train loss: 3.42764, test loss: 3.43187, slope: -0.733, stopping count: 0\n",
      "Epoch: 824, train loss: 3.42778, test loss: 3.43174, slope: -0.735, stopping count: 0\n",
      "Epoch: 825, train loss: 3.42766, test loss: 3.43178, slope: -0.734, stopping count: 0\n",
      "Epoch: 826, train loss: 3.42767, test loss: 3.43174, slope: -0.735, stopping count: 0\n",
      "Epoch: 827, train loss: 3.42771, test loss: 3.43204, slope: -0.733, stopping count: 0\n",
      "Epoch: 828, train loss: 3.42769, test loss: 3.43155, slope: -0.713, stopping count: 0\n",
      "Epoch: 829, train loss: 3.42767, test loss: 3.43185, slope: -0.798, stopping count: 0\n",
      "Epoch: 830, train loss: 3.42776, test loss: 3.43160, slope: -0.800, stopping count: 0\n",
      "Epoch: 831, train loss: 3.42773, test loss: 3.43173, slope: -0.800, stopping count: 0\n",
      "Epoch: 832, train loss: 3.42759, test loss: 3.43151, slope: -0.795, stopping count: 0\n",
      "Epoch: 833, train loss: 3.42763, test loss: 3.43204, slope: -0.792, stopping count: 0\n",
      "Epoch: 834, train loss: 3.42753, test loss: 3.43196, slope: -0.792, stopping count: 0\n",
      "Epoch: 835, train loss: 3.42757, test loss: 3.43165, slope: -0.792, stopping count: 0\n",
      "Epoch: 836, train loss: 3.42752, test loss: 3.43276, slope: -0.789, stopping count: 0\n",
      "Epoch: 837, train loss: 3.42761, test loss: 3.43181, slope: -0.788, stopping count: 0\n",
      "Epoch: 838, train loss: 3.42756, test loss: 3.43162, slope: -0.790, stopping count: 0\n",
      "Epoch: 839, train loss: 3.42767, test loss: 3.43188, slope: -0.787, stopping count: 0\n",
      "Epoch: 840, train loss: 3.42757, test loss: 3.43303, slope: -0.783, stopping count: 0\n",
      "Epoch: 841, train loss: 3.42787, test loss: 3.43186, slope: -0.781, stopping count: 0\n",
      "Epoch: 842, train loss: 3.42755, test loss: 3.43170, slope: -0.782, stopping count: 0\n",
      "Epoch: 843, train loss: 3.42747, test loss: 3.43169, slope: -0.781, stopping count: 0\n",
      "Epoch: 844, train loss: 3.42745, test loss: 3.43212, slope: -0.781, stopping count: 0\n",
      "Epoch: 845, train loss: 3.42756, test loss: 3.43163, slope: -0.781, stopping count: 0\n",
      "Epoch: 846, train loss: 3.42747, test loss: 3.43166, slope: -0.782, stopping count: 0\n",
      "Epoch: 847, train loss: 3.42743, test loss: 3.43170, slope: -0.782, stopping count: 0\n",
      "Epoch: 848, train loss: 3.42747, test loss: 3.43157, slope: -0.784, stopping count: 0\n",
      "Epoch: 849, train loss: 3.42747, test loss: 3.43197, slope: -0.780, stopping count: 0\n",
      "Epoch: 850, train loss: 3.42753, test loss: 3.43177, slope: -0.781, stopping count: 0\n",
      "Epoch: 851, train loss: 3.42774, test loss: 3.43217, slope: -0.778, stopping count: 0\n",
      "Epoch: 852, train loss: 3.42754, test loss: 3.43176, slope: -0.779, stopping count: 0\n",
      "Epoch: 853, train loss: 3.42754, test loss: 3.43188, slope: -0.776, stopping count: 0\n",
      "Epoch: 854, train loss: 3.42749, test loss: 3.43156, slope: -0.778, stopping count: 0\n",
      "Epoch: 855, train loss: 3.42738, test loss: 3.43170, slope: -0.777, stopping count: 0\n",
      "Epoch: 856, train loss: 3.42760, test loss: 3.43156, slope: -0.779, stopping count: 0\n",
      "Epoch: 857, train loss: 3.42736, test loss: 3.43186, slope: -0.777, stopping count: 0\n",
      "Epoch: 858, train loss: 3.42742, test loss: 3.43130, slope: -0.737, stopping count: 0\n",
      "Epoch: 859, train loss: 3.42739, test loss: 3.43182, slope: -0.734, stopping count: 0\n",
      "Epoch: 860, train loss: 3.42750, test loss: 3.43177, slope: -0.735, stopping count: 0\n",
      "Epoch: 861, train loss: 3.42727, test loss: 3.43143, slope: -0.734, stopping count: 0\n",
      "Epoch: 862, train loss: 3.42735, test loss: 3.43151, slope: -0.736, stopping count: 0\n",
      "Epoch: 863, train loss: 3.42738, test loss: 3.43154, slope: -0.735, stopping count: 0\n",
      "Epoch: 864, train loss: 3.42744, test loss: 3.43161, slope: -0.736, stopping count: 0\n",
      "Epoch: 865, train loss: 3.42727, test loss: 3.43156, slope: -0.736, stopping count: 0\n",
      "Epoch: 866, train loss: 3.42737, test loss: 3.43163, slope: -0.737, stopping count: 0\n",
      "Epoch: 867, train loss: 3.42734, test loss: 3.43182, slope: -0.736, stopping count: 0\n",
      "Epoch: 868, train loss: 3.42729, test loss: 3.43175, slope: -0.737, stopping count: 0\n",
      "Epoch: 869, train loss: 3.42746, test loss: 3.43168, slope: -0.735, stopping count: 0\n",
      "Epoch: 870, train loss: 3.42730, test loss: 3.43148, slope: -0.737, stopping count: 0\n",
      "Epoch: 871, train loss: 3.42739, test loss: 3.43175, slope: -0.735, stopping count: 0\n",
      "Epoch: 872, train loss: 3.42728, test loss: 3.43165, slope: -0.736, stopping count: 0\n",
      "Epoch: 873, train loss: 3.42722, test loss: 3.43149, slope: -0.733, stopping count: 0\n",
      "Epoch: 874, train loss: 3.42717, test loss: 3.43160, slope: -0.734, stopping count: 0\n",
      "Epoch: 875, train loss: 3.42732, test loss: 3.43169, slope: -0.732, stopping count: 0\n",
      "Epoch: 876, train loss: 3.42721, test loss: 3.43159, slope: -0.733, stopping count: 0\n",
      "Epoch: 877, train loss: 3.42730, test loss: 3.43150, slope: -0.733, stopping count: 0\n",
      "Epoch: 878, train loss: 3.42732, test loss: 3.43153, slope: -0.734, stopping count: 0\n",
      "Epoch: 879, train loss: 3.42726, test loss: 3.43149, slope: -0.733, stopping count: 0\n",
      "Epoch: 880, train loss: 3.42730, test loss: 3.43124, slope: -0.724, stopping count: 0\n",
      "Epoch: 881, train loss: 3.42716, test loss: 3.43161, slope: -0.723, stopping count: 0\n",
      "Epoch: 882, train loss: 3.42735, test loss: 3.43153, slope: -0.724, stopping count: 0\n",
      "Epoch: 883, train loss: 3.42731, test loss: 3.43157, slope: -0.723, stopping count: 0\n",
      "Epoch: 884, train loss: 3.42716, test loss: 3.43182, slope: -0.723, stopping count: 0\n",
      "Epoch: 885, train loss: 3.42722, test loss: 3.43136, slope: -0.723, stopping count: 0\n",
      "Epoch: 886, train loss: 3.42714, test loss: 3.43132, slope: -0.725, stopping count: 0\n",
      "Epoch: 887, train loss: 3.42712, test loss: 3.43164, slope: -0.723, stopping count: 0\n",
      "Epoch: 888, train loss: 3.42719, test loss: 3.43150, slope: -0.725, stopping count: 0\n",
      "Epoch: 889, train loss: 3.42709, test loss: 3.43138, slope: -0.724, stopping count: 0\n",
      "Epoch: 890, train loss: 3.42713, test loss: 3.43135, slope: -0.726, stopping count: 0\n",
      "Epoch: 891, train loss: 3.42716, test loss: 3.43157, slope: -0.725, stopping count: 0\n",
      "Epoch: 892, train loss: 3.42718, test loss: 3.43149, slope: -0.726, stopping count: 0\n",
      "Epoch: 893, train loss: 3.42713, test loss: 3.43140, slope: -0.725, stopping count: 0\n",
      "Epoch: 894, train loss: 3.42700, test loss: 3.43118, slope: -0.716, stopping count: 0\n",
      "Epoch: 895, train loss: 3.42713, test loss: 3.43126, slope: -0.716, stopping count: 0\n",
      "Epoch: 896, train loss: 3.42711, test loss: 3.43118, slope: -0.718, stopping count: 0\n",
      "Epoch: 897, train loss: 3.42700, test loss: 3.43145, slope: -0.718, stopping count: 0\n",
      "Epoch: 898, train loss: 3.42718, test loss: 3.43205, slope: -0.717, stopping count: 0\n",
      "Epoch: 899, train loss: 3.42726, test loss: 3.43146, slope: -0.715, stopping count: 0\n",
      "Epoch: 900, train loss: 3.42720, test loss: 3.43146, slope: -0.717, stopping count: 0\n",
      "Epoch: 901, train loss: 3.42710, test loss: 3.43135, slope: -0.715, stopping count: 0\n",
      "Epoch: 902, train loss: 3.42705, test loss: 3.43205, slope: -0.715, stopping count: 0\n",
      "Epoch: 903, train loss: 3.42713, test loss: 3.43135, slope: -0.836, stopping count: 0\n",
      "Epoch: 904, train loss: 3.42694, test loss: 3.43135, slope: -0.838, stopping count: 0\n",
      "Epoch: 905, train loss: 3.42713, test loss: 3.43133, slope: -0.837, stopping count: 0\n",
      "Epoch: 906, train loss: 3.42710, test loss: 3.43139, slope: -0.838, stopping count: 0\n",
      "Epoch: 907, train loss: 3.42697, test loss: 3.43134, slope: -0.837, stopping count: 0\n",
      "Epoch: 908, train loss: 3.42707, test loss: 3.43120, slope: -0.839, stopping count: 0\n",
      "Epoch: 909, train loss: 3.42706, test loss: 3.43130, slope: -0.838, stopping count: 0\n",
      "Epoch: 910, train loss: 3.42706, test loss: 3.43144, slope: -0.840, stopping count: 0\n",
      "Epoch: 911, train loss: 3.42703, test loss: 3.43136, slope: -0.839, stopping count: 0\n",
      "Epoch: 912, train loss: 3.42691, test loss: 3.43145, slope: -0.840, stopping count: 0\n",
      "Epoch: 913, train loss: 3.42697, test loss: 3.43120, slope: -0.840, stopping count: 0\n",
      "Epoch: 914, train loss: 3.42695, test loss: 3.43124, slope: -0.842, stopping count: 0\n",
      "Epoch: 915, train loss: 3.42693, test loss: 3.43154, slope: -0.839, stopping count: 0\n",
      "Epoch: 916, train loss: 3.42696, test loss: 3.43125, slope: -0.841, stopping count: 0\n",
      "Epoch: 917, train loss: 3.42700, test loss: 3.43210, slope: -0.837, stopping count: 0\n",
      "Epoch: 918, train loss: 3.42708, test loss: 3.43131, slope: -0.838, stopping count: 0\n",
      "Epoch: 919, train loss: 3.42704, test loss: 3.43125, slope: -0.838, stopping count: 0\n",
      "Epoch: 920, train loss: 3.42698, test loss: 3.43140, slope: -0.839, stopping count: 0\n",
      "Epoch: 921, train loss: 3.42694, test loss: 3.43126, slope: -0.838, stopping count: 0\n",
      "Epoch: 922, train loss: 3.42689, test loss: 3.43125, slope: -0.840, stopping count: 0\n",
      "Epoch: 923, train loss: 3.42711, test loss: 3.43141, slope: -0.839, stopping count: 0\n",
      "Epoch: 924, train loss: 3.42704, test loss: 3.43163, slope: -0.839, stopping count: 0\n",
      "Epoch: 925, train loss: 3.42709, test loss: 3.43148, slope: -0.836, stopping count: 0\n",
      "Epoch: 926, train loss: 3.42704, test loss: 3.43135, slope: -0.837, stopping count: 0\n",
      "Epoch: 927, train loss: 3.42680, test loss: 3.43154, slope: -0.835, stopping count: 0\n",
      "Epoch: 928, train loss: 3.42684, test loss: 3.43132, slope: -0.836, stopping count: 0\n",
      "Epoch: 929, train loss: 3.42688, test loss: 3.43169, slope: -0.833, stopping count: 0\n",
      "Epoch: 930, train loss: 3.42686, test loss: 3.43176, slope: -0.833, stopping count: 0\n",
      "Epoch: 931, train loss: 3.42677, test loss: 3.43142, slope: -0.832, stopping count: 0\n",
      "Epoch: 932, train loss: 3.42687, test loss: 3.43108, slope: -0.808, stopping count: 0\n",
      "Epoch: 933, train loss: 3.42683, test loss: 3.43123, slope: -0.807, stopping count: 0\n",
      "Epoch: 934, train loss: 3.42692, test loss: 3.43117, slope: -0.809, stopping count: 0\n",
      "Epoch: 935, train loss: 3.42690, test loss: 3.43129, slope: -0.808, stopping count: 0\n",
      "Epoch: 936, train loss: 3.42682, test loss: 3.43176, slope: -0.808, stopping count: 0\n",
      "Epoch: 937, train loss: 3.42677, test loss: 3.43129, slope: -0.807, stopping count: 0\n",
      "Epoch: 938, train loss: 3.42691, test loss: 3.43126, slope: -0.808, stopping count: 0\n",
      "Epoch: 939, train loss: 3.42682, test loss: 3.43123, slope: -0.806, stopping count: 0\n",
      "Epoch: 940, train loss: 3.42693, test loss: 3.43125, slope: -0.808, stopping count: 0\n",
      "Epoch: 941, train loss: 3.42693, test loss: 3.43122, slope: -0.807, stopping count: 0\n",
      "Epoch: 942, train loss: 3.42676, test loss: 3.43114, slope: -0.808, stopping count: 0\n",
      "Epoch: 943, train loss: 3.42701, test loss: 3.43122, slope: -0.807, stopping count: 0\n",
      "Epoch: 944, train loss: 3.42684, test loss: 3.43136, slope: -0.808, stopping count: 0\n",
      "Epoch: 945, train loss: 3.42696, test loss: 3.43135, slope: -0.806, stopping count: 0\n",
      "Epoch: 946, train loss: 3.42679, test loss: 3.43118, slope: -0.807, stopping count: 0\n",
      "Epoch: 947, train loss: 3.42678, test loss: 3.43121, slope: -0.805, stopping count: 0\n",
      "Epoch: 948, train loss: 3.42674, test loss: 3.43136, slope: -0.806, stopping count: 0\n",
      "Epoch: 949, train loss: 3.42666, test loss: 3.43126, slope: -0.805, stopping count: 0\n",
      "Epoch: 950, train loss: 3.42668, test loss: 3.43119, slope: -0.807, stopping count: 0\n",
      "Epoch: 951, train loss: 3.42668, test loss: 3.43114, slope: -0.806, stopping count: 0\n",
      "Epoch: 952, train loss: 3.42681, test loss: 3.43136, slope: -0.807, stopping count: 0\n",
      "Epoch: 953, train loss: 3.42657, test loss: 3.43121, slope: -0.805, stopping count: 0\n",
      "Epoch: 954, train loss: 3.42682, test loss: 3.43112, slope: -0.807, stopping count: 0\n",
      "Epoch: 955, train loss: 3.42670, test loss: 3.43158, slope: -0.804, stopping count: 0\n",
      "Epoch: 956, train loss: 3.42664, test loss: 3.43109, slope: -0.806, stopping count: 0\n",
      "Epoch: 957, train loss: 3.42672, test loss: 3.43126, slope: -0.804, stopping count: 0\n",
      "Epoch: 958, train loss: 3.42672, test loss: 3.43164, slope: -0.803, stopping count: 0\n",
      "Epoch: 959, train loss: 3.42681, test loss: 3.43200, slope: -0.800, stopping count: 0\n",
      "Epoch: 960, train loss: 3.42663, test loss: 3.43088, slope: -0.759, stopping count: 0\n",
      "Epoch: 961, train loss: 3.42680, test loss: 3.43100, slope: -0.759, stopping count: 0\n",
      "Epoch: 962, train loss: 3.42662, test loss: 3.43097, slope: -0.761, stopping count: 0\n",
      "Epoch: 963, train loss: 3.42660, test loss: 3.43151, slope: -0.759, stopping count: 0\n",
      "Epoch: 964, train loss: 3.42660, test loss: 3.43105, slope: -0.760, stopping count: 0\n",
      "Epoch: 965, train loss: 3.42687, test loss: 3.43136, slope: -0.759, stopping count: 0\n",
      "Epoch: 966, train loss: 3.42668, test loss: 3.43126, slope: -0.760, stopping count: 0\n",
      "Epoch: 967, train loss: 3.42669, test loss: 3.43099, slope: -0.759, stopping count: 0\n",
      "Epoch: 968, train loss: 3.42657, test loss: 3.43112, slope: -0.760, stopping count: 0\n",
      "Epoch: 969, train loss: 3.42670, test loss: 3.43117, slope: -0.760, stopping count: 0\n",
      "Epoch: 970, train loss: 3.42669, test loss: 3.43108, slope: -0.761, stopping count: 0\n",
      "Epoch: 971, train loss: 3.42662, test loss: 3.43205, slope: -0.757, stopping count: 0\n",
      "Epoch: 972, train loss: 3.42663, test loss: 3.43103, slope: -0.759, stopping count: 0\n",
      "Epoch: 973, train loss: 3.42676, test loss: 3.43114, slope: -0.758, stopping count: 0\n",
      "Epoch: 974, train loss: 3.42656, test loss: 3.43104, slope: -0.759, stopping count: 0\n",
      "Epoch: 975, train loss: 3.42655, test loss: 3.43132, slope: -0.757, stopping count: 0\n",
      "Epoch: 976, train loss: 3.42667, test loss: 3.43117, slope: -0.758, stopping count: 0\n",
      "Epoch: 977, train loss: 3.42674, test loss: 3.43140, slope: -0.757, stopping count: 0\n",
      "Epoch: 978, train loss: 3.42652, test loss: 3.43086, slope: -0.754, stopping count: 0\n",
      "Epoch: 979, train loss: 3.42657, test loss: 3.43113, slope: -0.753, stopping count: 0\n",
      "Epoch: 980, train loss: 3.42663, test loss: 3.43173, slope: -0.752, stopping count: 0\n",
      "Epoch: 981, train loss: 3.42674, test loss: 3.43118, slope: -0.751, stopping count: 0\n",
      "Epoch: 982, train loss: 3.42654, test loss: 3.43127, slope: -0.752, stopping count: 0\n",
      "Epoch: 983, train loss: 3.42650, test loss: 3.43153, slope: -0.749, stopping count: 0\n",
      "Epoch: 984, train loss: 3.42658, test loss: 3.43114, slope: -0.750, stopping count: 0\n",
      "Epoch: 985, train loss: 3.42653, test loss: 3.43135, slope: -0.747, stopping count: 0\n",
      "Epoch: 986, train loss: 3.42659, test loss: 3.43113, slope: -0.748, stopping count: 0\n",
      "Epoch: 987, train loss: 3.42641, test loss: 3.43122, slope: -0.747, stopping count: 0\n",
      "Epoch: 988, train loss: 3.42650, test loss: 3.43087, slope: -0.748, stopping count: 0\n",
      "Epoch: 989, train loss: 3.42662, test loss: 3.43138, slope: -0.746, stopping count: 0\n",
      "Epoch: 990, train loss: 3.42659, test loss: 3.43091, slope: -0.748, stopping count: 0\n",
      "Epoch: 991, train loss: 3.42652, test loss: 3.43109, slope: -0.745, stopping count: 0\n",
      "Epoch: 992, train loss: 3.42644, test loss: 3.43116, slope: -0.746, stopping count: 0\n",
      "Epoch: 993, train loss: 3.42649, test loss: 3.43124, slope: -0.745, stopping count: 0\n",
      "Epoch: 994, train loss: 3.42656, test loss: 3.43109, slope: -0.746, stopping count: 0\n",
      "Epoch: 995, train loss: 3.42640, test loss: 3.43178, slope: -0.743, stopping count: 0\n",
      "Epoch: 996, train loss: 3.42654, test loss: 3.43116, slope: -0.743, stopping count: 0\n",
      "Epoch: 997, train loss: 3.42654, test loss: 3.43111, slope: -0.741, stopping count: 0\n",
      "Epoch: 998, train loss: 3.42639, test loss: 3.43125, slope: -0.742, stopping count: 0\n",
      "Epoch: 999, train loss: 3.42656, test loss: 3.43107, slope: -0.741, stopping count: 0\n",
      "Epoch: 1000, train loss: 3.42649, test loss: 3.43107, slope: -0.742, stopping count: 0\n",
      "Epoch: 1001, train loss: 3.42629, test loss: 3.43099, slope: -0.741, stopping count: 0\n",
      "Epoch: 1002, train loss: 3.42641, test loss: 3.43128, slope: -0.741, stopping count: 0\n",
      "Epoch: 1003, train loss: 3.42654, test loss: 3.43155, slope: -0.739, stopping count: 0\n",
      "Epoch: 1004, train loss: 3.42654, test loss: 3.43098, slope: -0.740, stopping count: 0\n",
      "Epoch: 1005, train loss: 3.42638, test loss: 3.43097, slope: -0.739, stopping count: 0\n",
      "Epoch: 1006, train loss: 3.42645, test loss: 3.43080, slope: -0.729, stopping count: 0\n",
      "Epoch: 1007, train loss: 3.42631, test loss: 3.43105, slope: -0.728, stopping count: 0\n",
      "Epoch: 1008, train loss: 3.42633, test loss: 3.43096, slope: -0.729, stopping count: 0\n",
      "Epoch: 1009, train loss: 3.42647, test loss: 3.43100, slope: -0.728, stopping count: 0\n",
      "Epoch: 1010, train loss: 3.42644, test loss: 3.43094, slope: -0.729, stopping count: 0\n",
      "Epoch: 1011, train loss: 3.42637, test loss: 3.43104, slope: -0.729, stopping count: 0\n",
      "Epoch: 1012, train loss: 3.42660, test loss: 3.43117, slope: -0.729, stopping count: 0\n",
      "Epoch: 1013, train loss: 3.42639, test loss: 3.43097, slope: -0.728, stopping count: 0\n",
      "Epoch: 1014, train loss: 3.42642, test loss: 3.43125, slope: -0.728, stopping count: 0\n",
      "Epoch: 1015, train loss: 3.42647, test loss: 3.43100, slope: -0.727, stopping count: 0\n",
      "Epoch: 1016, train loss: 3.42616, test loss: 3.43122, slope: -0.727, stopping count: 0\n",
      "Epoch: 1017, train loss: 3.42658, test loss: 3.43110, slope: -0.726, stopping count: 0\n",
      "Epoch: 1018, train loss: 3.42646, test loss: 3.43093, slope: -0.727, stopping count: 0\n",
      "Epoch: 1019, train loss: 3.42632, test loss: 3.43092, slope: -0.726, stopping count: 0\n",
      "Epoch: 1020, train loss: 3.42634, test loss: 3.43081, slope: -0.728, stopping count: 0\n",
      "Epoch: 1021, train loss: 3.42636, test loss: 3.43117, slope: -0.727, stopping count: 0\n",
      "Epoch: 1022, train loss: 3.42634, test loss: 3.43099, slope: -0.728, stopping count: 0\n",
      "Epoch: 1023, train loss: 3.42626, test loss: 3.43107, slope: -0.727, stopping count: 0\n",
      "Epoch: 1024, train loss: 3.42634, test loss: 3.43089, slope: -0.728, stopping count: 0\n",
      "Epoch: 1025, train loss: 3.42635, test loss: 3.43141, slope: -0.726, stopping count: 0\n",
      "Epoch: 1026, train loss: 3.42644, test loss: 3.43103, slope: -0.727, stopping count: 0\n",
      "Epoch: 1027, train loss: 3.42622, test loss: 3.43105, slope: -0.774, stopping count: 0\n",
      "Epoch: 1028, train loss: 3.42625, test loss: 3.43093, slope: -0.776, stopping count: 0\n",
      "Epoch: 1029, train loss: 3.42629, test loss: 3.43087, slope: -0.774, stopping count: 0\n",
      "Epoch: 1030, train loss: 3.42628, test loss: 3.43082, slope: -0.776, stopping count: 0\n",
      "Epoch: 1031, train loss: 3.42628, test loss: 3.43096, slope: -0.775, stopping count: 0\n",
      "Epoch: 1032, train loss: 3.42635, test loss: 3.43091, slope: -0.776, stopping count: 0\n",
      "Epoch: 1033, train loss: 3.42628, test loss: 3.43101, slope: -0.774, stopping count: 0\n",
      "Epoch: 1034, train loss: 3.42619, test loss: 3.43108, slope: -0.775, stopping count: 0\n",
      "Epoch: 1035, train loss: 3.42627, test loss: 3.43114, slope: -0.773, stopping count: 0\n",
      "Epoch: 1036, train loss: 3.42627, test loss: 3.43081, slope: -0.774, stopping count: 0\n",
      "Epoch: 1037, train loss: 3.42632, test loss: 3.43103, slope: -0.773, stopping count: 0\n",
      "Epoch: 1038, train loss: 3.42626, test loss: 3.43096, slope: -0.774, stopping count: 0\n",
      "Epoch: 1039, train loss: 3.42620, test loss: 3.43085, slope: -0.772, stopping count: 0\n",
      "Epoch: 1040, train loss: 3.42633, test loss: 3.43121, slope: -0.773, stopping count: 0\n",
      "Epoch: 1041, train loss: 3.42607, test loss: 3.43095, slope: -0.771, stopping count: 0\n",
      "Epoch: 1042, train loss: 3.42623, test loss: 3.43113, slope: -0.771, stopping count: 0\n",
      "Epoch: 1043, train loss: 3.42611, test loss: 3.43091, slope: -0.771, stopping count: 0\n",
      "Epoch: 1044, train loss: 3.42630, test loss: 3.43170, slope: -0.769, stopping count: 0\n",
      "Epoch: 1045, train loss: 3.42647, test loss: 3.43097, slope: -0.768, stopping count: 0\n",
      "Epoch: 1046, train loss: 3.42612, test loss: 3.43106, slope: -0.769, stopping count: 0\n",
      "Epoch: 1047, train loss: 3.42638, test loss: 3.43083, slope: -0.769, stopping count: 0\n",
      "Epoch: 1048, train loss: 3.42625, test loss: 3.43091, slope: -0.770, stopping count: 0\n",
      "Epoch: 1049, train loss: 3.42613, test loss: 3.43140, slope: -0.767, stopping count: 0\n",
      "Epoch: 1050, train loss: 3.42625, test loss: 3.43112, slope: -0.768, stopping count: 0\n",
      "Epoch: 1051, train loss: 3.42620, test loss: 3.43094, slope: -0.831, stopping count: 0\n",
      "Epoch: 1052, train loss: 3.42613, test loss: 3.43086, slope: -0.832, stopping count: 0\n",
      "Epoch: 1053, train loss: 3.42615, test loss: 3.43116, slope: -0.831, stopping count: 0\n",
      "Epoch: 1054, train loss: 3.42613, test loss: 3.43092, slope: -0.832, stopping count: 0\n",
      "Epoch: 1055, train loss: 3.42629, test loss: 3.43117, slope: -0.830, stopping count: 0\n",
      "Epoch: 1056, train loss: 3.42619, test loss: 3.43086, slope: -0.831, stopping count: 0\n",
      "Epoch: 1057, train loss: 3.42611, test loss: 3.43085, slope: -0.830, stopping count: 0\n",
      "Epoch: 1058, train loss: 3.42619, test loss: 3.43100, slope: -0.831, stopping count: 0\n",
      "Epoch: 1059, train loss: 3.42609, test loss: 3.43079, slope: -0.829, stopping count: 0\n",
      "Epoch: 1060, train loss: 3.42609, test loss: 3.43087, slope: -0.830, stopping count: 0\n",
      "Epoch: 1061, train loss: 3.42600, test loss: 3.43114, slope: -0.827, stopping count: 0\n",
      "Epoch: 1062, train loss: 3.42622, test loss: 3.43131, slope: -0.826, stopping count: 0\n",
      "Epoch: 1063, train loss: 3.42609, test loss: 3.43087, slope: -0.825, stopping count: 0\n",
      "Epoch: 1064, train loss: 3.42603, test loss: 3.43105, slope: -0.826, stopping count: 0\n",
      "Epoch: 1065, train loss: 3.42606, test loss: 3.43116, slope: -0.824, stopping count: 0\n",
      "Epoch: 1066, train loss: 3.42624, test loss: 3.43094, slope: -0.824, stopping count: 0\n",
      "Epoch: 1067, train loss: 3.42606, test loss: 3.43072, slope: -0.805, stopping count: 0\n",
      "Epoch: 1068, train loss: 3.42608, test loss: 3.43068, slope: -0.797, stopping count: 0\n",
      "Epoch: 1069, train loss: 3.42610, test loss: 3.43092, slope: -0.796, stopping count: 0\n",
      "Epoch: 1070, train loss: 3.42608, test loss: 3.43092, slope: -0.797, stopping count: 0\n",
      "Epoch: 1071, train loss: 3.42624, test loss: 3.43121, slope: -0.796, stopping count: 0\n",
      "Epoch: 1072, train loss: 3.42618, test loss: 3.43072, slope: -0.797, stopping count: 0\n",
      "Epoch: 1073, train loss: 3.42607, test loss: 3.43092, slope: -0.796, stopping count: 0\n",
      "Epoch: 1074, train loss: 3.42612, test loss: 3.43095, slope: -0.796, stopping count: 0\n",
      "Epoch: 1075, train loss: 3.42615, test loss: 3.43089, slope: -0.796, stopping count: 0\n",
      "Epoch: 1076, train loss: 3.42606, test loss: 3.43082, slope: -0.797, stopping count: 0\n",
      "Epoch: 1077, train loss: 3.42593, test loss: 3.43107, slope: -0.795, stopping count: 0\n",
      "Epoch: 1078, train loss: 3.42615, test loss: 3.43094, slope: -0.795, stopping count: 0\n",
      "Epoch: 1079, train loss: 3.42616, test loss: 3.43082, slope: -0.794, stopping count: 0\n",
      "Epoch: 1080, train loss: 3.42600, test loss: 3.43082, slope: -0.795, stopping count: 0\n",
      "Epoch: 1081, train loss: 3.42615, test loss: 3.43159, slope: -0.791, stopping count: 0\n",
      "Epoch: 1082, train loss: 3.42602, test loss: 3.43089, slope: -0.792, stopping count: 0\n",
      "Epoch: 1083, train loss: 3.42629, test loss: 3.43085, slope: -0.790, stopping count: 0\n",
      "Epoch: 1084, train loss: 3.42589, test loss: 3.43082, slope: -0.791, stopping count: 0\n",
      "Epoch: 1085, train loss: 3.42626, test loss: 3.43102, slope: -0.789, stopping count: 0\n",
      "Epoch: 1086, train loss: 3.42600, test loss: 3.43068, slope: -0.790, stopping count: 0\n",
      "Epoch: 1087, train loss: 3.42590, test loss: 3.43088, slope: -0.791, stopping count: 0\n",
      "Epoch: 1088, train loss: 3.42595, test loss: 3.43085, slope: -0.792, stopping count: 0\n",
      "Epoch: 1089, train loss: 3.42605, test loss: 3.43081, slope: -0.791, stopping count: 0\n",
      "Epoch: 1090, train loss: 3.42601, test loss: 3.43065, slope: -0.787, stopping count: 0\n",
      "Epoch: 1091, train loss: 3.42595, test loss: 3.43068, slope: -0.787, stopping count: 0\n",
      "Epoch: 1092, train loss: 3.42596, test loss: 3.43108, slope: -0.787, stopping count: 0\n",
      "Epoch: 1093, train loss: 3.42591, test loss: 3.43065, slope: -0.785, stopping count: 0\n",
      "Epoch: 1094, train loss: 3.42593, test loss: 3.43099, slope: -0.785, stopping count: 0\n",
      "Epoch: 1095, train loss: 3.42591, test loss: 3.43082, slope: -0.784, stopping count: 0\n",
      "Epoch: 1096, train loss: 3.42596, test loss: 3.43106, slope: -0.785, stopping count: 0\n",
      "Epoch: 1097, train loss: 3.42587, test loss: 3.43093, slope: -0.783, stopping count: 0\n",
      "Epoch: 1098, train loss: 3.42599, test loss: 3.43071, slope: -0.784, stopping count: 0\n",
      "Epoch: 1099, train loss: 3.42599, test loss: 3.43094, slope: -0.783, stopping count: 0\n",
      "Epoch: 1100, train loss: 3.42591, test loss: 3.43084, slope: -0.784, stopping count: 0\n",
      "Epoch: 1101, train loss: 3.42589, test loss: 3.43081, slope: -0.783, stopping count: 0\n",
      "Epoch: 1102, train loss: 3.42602, test loss: 3.43064, slope: -0.782, stopping count: 0\n",
      "Epoch: 1103, train loss: 3.42587, test loss: 3.43080, slope: -0.781, stopping count: 0\n",
      "Epoch: 1104, train loss: 3.42601, test loss: 3.43101, slope: -0.781, stopping count: 0\n",
      "Epoch: 1105, train loss: 3.42609, test loss: 3.43077, slope: -0.781, stopping count: 0\n",
      "Epoch: 1106, train loss: 3.42576, test loss: 3.43065, slope: -0.782, stopping count: 0\n",
      "Epoch: 1107, train loss: 3.42601, test loss: 3.43082, slope: -0.780, stopping count: 0\n",
      "Epoch: 1108, train loss: 3.42594, test loss: 3.43080, slope: -0.781, stopping count: 0\n",
      "Epoch: 1109, train loss: 3.42589, test loss: 3.43073, slope: -0.780, stopping count: 0\n",
      "Epoch: 1110, train loss: 3.42587, test loss: 3.43079, slope: -0.780, stopping count: 0\n",
      "Epoch: 1111, train loss: 3.42598, test loss: 3.43117, slope: -0.779, stopping count: 0\n",
      "Epoch: 1112, train loss: 3.42583, test loss: 3.43097, slope: -0.779, stopping count: 0\n",
      "Epoch: 1113, train loss: 3.42601, test loss: 3.43071, slope: -0.778, stopping count: 0\n",
      "Epoch: 1114, train loss: 3.42583, test loss: 3.43068, slope: -0.779, stopping count: 0\n",
      "Epoch: 1115, train loss: 3.42589, test loss: 3.43082, slope: -0.778, stopping count: 0\n",
      "Epoch: 1116, train loss: 3.42597, test loss: 3.43074, slope: -0.778, stopping count: 0\n",
      "Epoch: 1117, train loss: 3.42592, test loss: 3.43063, slope: -0.775, stopping count: 0\n",
      "Epoch: 1118, train loss: 3.42587, test loss: 3.43110, slope: -0.774, stopping count: 0\n",
      "Epoch: 1119, train loss: 3.42584, test loss: 3.43088, slope: -0.773, stopping count: 0\n",
      "Epoch: 1120, train loss: 3.42581, test loss: 3.43060, slope: -0.768, stopping count: 0\n",
      "Epoch: 1121, train loss: 3.42585, test loss: 3.43080, slope: -0.767, stopping count: 0\n",
      "Epoch: 1122, train loss: 3.42605, test loss: 3.43060, slope: -0.767, stopping count: 0\n",
      "Epoch: 1123, train loss: 3.42587, test loss: 3.43058, slope: -0.762, stopping count: 0\n",
      "Epoch: 1124, train loss: 3.42577, test loss: 3.43090, slope: -0.763, stopping count: 0\n",
      "Epoch: 1125, train loss: 3.42605, test loss: 3.43081, slope: -0.762, stopping count: 0\n",
      "Epoch: 1126, train loss: 3.42576, test loss: 3.43073, slope: -0.762, stopping count: 0\n",
      "Epoch: 1127, train loss: 3.42591, test loss: 3.43062, slope: -0.761, stopping count: 0\n",
      "Epoch: 1128, train loss: 3.42590, test loss: 3.43061, slope: -0.762, stopping count: 0\n",
      "Epoch: 1129, train loss: 3.42578, test loss: 3.43052, slope: -0.748, stopping count: 0\n",
      "Epoch: 1130, train loss: 3.42589, test loss: 3.43043, slope: -0.732, stopping count: 0\n",
      "Epoch: 1131, train loss: 3.42572, test loss: 3.43065, slope: -0.731, stopping count: 0\n",
      "Epoch: 1132, train loss: 3.42576, test loss: 3.43065, slope: -0.732, stopping count: 0\n",
      "Epoch: 1133, train loss: 3.42576, test loss: 3.43064, slope: -0.732, stopping count: 0\n",
      "Epoch: 1134, train loss: 3.42585, test loss: 3.43053, slope: -0.733, stopping count: 0\n",
      "Epoch: 1135, train loss: 3.42576, test loss: 3.43081, slope: -0.732, stopping count: 0\n",
      "Epoch: 1136, train loss: 3.42596, test loss: 3.43065, slope: -0.733, stopping count: 0\n",
      "Epoch: 1137, train loss: 3.42577, test loss: 3.43096, slope: -0.732, stopping count: 0\n",
      "Epoch: 1138, train loss: 3.42568, test loss: 3.43064, slope: -0.733, stopping count: 0\n",
      "Epoch: 1139, train loss: 3.42585, test loss: 3.43066, slope: -0.731, stopping count: 0\n",
      "Epoch: 1140, train loss: 3.42572, test loss: 3.43056, slope: -0.733, stopping count: 0\n"
     ]
    }
   ],
   "source": [
    "import os, torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from chess_selfplay import harvest_checkmates\n",
    "from chess_model import TransformerModel, ChessDataset, TanhLoss, train\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "min_tournaments_each_round = 50 # A new model roughly once a day.\n",
    "model_kwargs = {'nlayers':6, 'nheads':3, 'embed_dim':12, 'dk':8, 'device':device}\n",
    "root_dir = os.path.join('data','output')\n",
    "dir_sort_key = lambda d: int(d.split('_')[-1])\n",
    "mode = 'continuous'\n",
    "\n",
    "## LOOP STARTS - just kill the machine any old time when you have stuff to do and you can fire it up again whenever you're ready.\n",
    "while True:\n",
    "\n",
    "    # Checking where we're up to\n",
    "    training_round_dirs = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir,d))], key=dir_sort_key)\n",
    "    current_training_round_dir = training_round_dirs[-1]\n",
    "    previous_training_round_dir = training_round_dirs[-2]\n",
    "\n",
    "    # Counting how many tournaments have been played already this round\n",
    "    current_self_play_path = os.path.join(root_dir, current_training_round_dir, 'self_play')\n",
    "    if os.path.exists(current_self_play_path) and os.path.isdir(current_self_play_path):\n",
    "        number_games_played_already = len(os.listdir(current_self_play_path))\n",
    "    else:\n",
    "        os.mkdir(current_self_play_path)\n",
    "        number_games_played_already = 0\n",
    "\n",
    "    tournaments_left_to_play = min_tournaments_each_round - number_games_played_already\n",
    "    print(f'Current: {current_training_round_dir}, already played: {number_games_played_already}, left to play: {tournaments_left_to_play}')\n",
    "\n",
    "    if tournaments_left_to_play > 0:\n",
    "        \n",
    "        # self-play script to play tournaments_left_to_play more tournaments, saving to current_self_play_dir.\n",
    "        previous_model_path = os.path.join(root_dir, previous_training_round_dir, 'model.pt')\n",
    "        assert os.path.exists(previous_model_path) and os.path.isfile(previous_model_path), 'ERROR: MODEL NOT FOUND.'\n",
    "\n",
    "        # Same base model with different look-ahead strength configuration \n",
    "        model_kwargs['load_path'] = previous_model_path\n",
    "        agent0_spec = {'type':'transformer', 'kwargs':model_kwargs, 'num_simgames':150, 'max_simmoves':6, 'C':1, 'p':0.3, 'k':float('inf')}\n",
    "        agent1_spec = {'type':'transformer', 'kwargs':model_kwargs, 'num_simgames':1,   'max_simmoves':1, 'C':1, 'p':0.4, 'k':float('inf')}\n",
    "        selfplay_args = {\n",
    "            'num_workers':2, 'num_tournaments': tournaments_left_to_play, 'agents_spec': [agent0_spec, agent1_spec], \n",
    "            'num_games':1, 'starting_state':None, 'max_moves':200, 'save':True, 'result_dest':current_self_play_path\n",
    "        }\n",
    "\n",
    "        # Let's play\n",
    "        print(f'Playing {tournaments_left_to_play} tournaments...')\n",
    "        %run -i \"chess_selfplay.py\"\n",
    "        print(f'Self-play complete.')\n",
    "\n",
    "    # Extract the checkmates from the current_self_play_dir tournament games and save them in the current_training_round_dir.\n",
    "    current_round_checkmates_path = os.path.join(root_dir, current_training_round_dir, 'checkmates.pkl')\n",
    "    if not (os.path.exists(current_round_checkmates_path) and os.path.isfile(current_round_checkmates_path)):\n",
    "        _ = harvest_checkmates(os.path.join(root_dir, current_training_round_dir))\n",
    "\n",
    "    ## Namespace for chess_modeltraining.py includes:\n",
    "    ## root_dir, current_training_round_dir, model_kwargs, device\n",
    "    # modeltraining_args = {'root_dir':root_dir, 'current_training_round_dir':current_training_round_dir, 'model_kwargs':model_kwargs, 'device':device}\n",
    "    # Let's train\n",
    "    # print(f'Training a new model...')\n",
    "    # %run -i \"chess_modeltraining.py\"\n",
    "    # print(f'Training complete.')\n",
    "\n",
    "    latest_model_path = os.path.join(root_dir, current_training_round_dir, 'model.pt')\n",
    "    if not (os.path.exists(latest_model_path) and os.path.isfile(latest_model_path)):\n",
    "\n",
    "        # No model saved here yet. Create and train a new model based on the previous k rounds of self-play data.\n",
    "        previous_model_path = os.path.join(root_dir, previous_training_round_dir, 'model.pt')\n",
    "        if mode == 'continuous' and os.path.exists(previous_model_path) and os.path.isfile(previous_model_path):\n",
    "            print('Training from model saved last round.')\n",
    "            model_kwargs['load_path'] = previous_model_path # Load previous generation model\n",
    "        else:\n",
    "            print('Training brand new model.')\n",
    "            model_kwargs['load_path'] = None # Brand new model\n",
    "\n",
    "        model = TransformerModel(**model_kwargs)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0, weight_decay=0)\n",
    "        loss_fn = TanhLoss()\n",
    "        dataset = ChessDataset(root_dir=root_dir, look_back=10, device=device)\n",
    "        train_set, test_set = random_split(dataset, [int(len(dataset)*0.8), len(dataset) - int(len(dataset)*0.8)])\n",
    "        train_loader = DataLoader(train_set, batch_size=1000, shuffle=True, num_workers=0)\n",
    "        test_loader = DataLoader(test_set, batch_size=1000, shuffle=True, num_workers=0)\n",
    "        print(f'Training on {len(train_set):,.0f} examples in {len(train_loader):,.0f} batches.')\n",
    "\n",
    "        # Train on the data\n",
    "        model_dest = os.path.join(root_dir, current_training_round_dir, 'model.pt')\n",
    "        model = train(model, loss_fn, optimizer, train_loader, test_loader, warmup_passes=4, max_lr=2e-4, save_dir=model_dest, slope_threshold=0, stop_after=20)\n",
    "        \n",
    "        # Clean up CUDA memory\n",
    "        del model, optimizer, loss_fn, dataset, train_set, test_set, train_loader, test_loader\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    torch.cuda.empty_cache() ## again maybe?\n",
    "        \n",
    "    # Create next training round directory containing self_play sub-directory, and start loop from the top.\n",
    "    next_index = int(os.path.split(current_training_round_dir)[-1].split('_')[-1]) + 1\n",
    "    next_training_round_dir = f'round_{next_index}'\n",
    "    print(f'Creating next training round directory {next_training_round_dir}')\n",
    "    next_training_round_path = os.path.join(root_dir, next_training_round_dir)\n",
    "    os.mkdir(next_training_round_path)\n",
    "    next_training_round_self_play_path = os.path.join(next_training_round_path, 'self_play')\n",
    "    os.mkdir(next_training_round_self_play_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090eddaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
